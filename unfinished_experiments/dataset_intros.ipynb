{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5117b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Random seed set to: 42\n",
      "p_values: [1, 2]\n",
      "q_values: [1, 2]\n",
      "Using device: cpu\n",
      "Random seed set to: 42\n",
      "p_values: [1, 2]\n",
      "q_values: [1, 2]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import modules.training as training\n",
    "importlib.reload(training)\n",
    "import modules.graph_vis as graph_vis\n",
    "importlib.reload(graph_vis)\n",
    "import modules.graph_creation as graph_creation\n",
    "importlib.reload(graph_creation)\n",
    "import modules.utils as utils\n",
    "importlib.reload(utils)\n",
    "import modules.train_n2v as train_n2v\n",
    "importlib.reload(train_n2v)\n",
    "\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3cb1ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the three Panetiod dataset\n",
    "dataset_cora,data_cora = training.load_dataset('Cora')\n",
    "dataset_citeseer,data_citeseer = training.load_dataset('Citeseer')\n",
    "dataset_pubmed,data_pubmed = training.load_dataset('Pubmed')\n",
    "\n",
    "list_of_datasets = [dataset_cora, dataset_citeseer, dataset_pubmed]\n",
    "list_of_data = [data_cora, data_citeseer, data_pubmed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58cc784a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting graph analytics\n",
      "[INFO] Graph is a PyTorch Geometric Data object, converting to NetworkX graph.\n",
      "\n",
      "----------Basic graph information-----------\n",
      "Type:  <class 'networkx.classes.digraph.DiGraph'>\n",
      "DiGraph with 2708 nodes and 10556 edges\n",
      "Number of nodes:  2708\n",
      "Number of edges:  10556\n",
      "Average node degree:  7.796159527326441\n",
      "Has isolated nodes:  0\n",
      "Has self loops:  0\n",
      "Is directed:  True\n",
      "Warning: Connected components and largest component stats not available for directed graphs.\n",
      "Error calculating Average Shortest Path (Largest Component): local variable 'largest_cc' referenced before assignment\n",
      "Error calculating Number of Connected Components: not implemented for directed type\n",
      "----------Graph extra statistics-----------\n",
      "Number of connected components: N/A (directed graph)\n",
      "Number of nodes in largest component: N/A (directed graph)\n",
      "Average Clustering Coefficient: 0.24067329850193728\n",
      "Transitivity/Global clustering coeff: 0.09349725626661058\n",
      "\n",
      "[INFO] Starting graph analytics\n",
      "[INFO] Graph is a PyTorch Geometric Data object, converting to NetworkX graph.\n",
      "\n",
      "----------Basic graph information-----------\n",
      "Type:  <class 'networkx.classes.digraph.DiGraph'>\n",
      "DiGraph with 3327 nodes and 9104 edges\n",
      "Number of nodes:  3327\n",
      "Number of edges:  9104\n",
      "Average node degree:  5.472798316801923\n",
      "Has isolated nodes:  48\n",
      "Has self loops:  0\n",
      "Is directed:  True\n",
      "Warning: Connected components and largest component stats not available for directed graphs.\n",
      "Error calculating Average Shortest Path (Largest Component): local variable 'largest_cc' referenced before assignment\n",
      "Error calculating Number of Connected Components: not implemented for directed type\n",
      "----------Graph extra statistics-----------\n",
      "Number of connected components: N/A (directed graph)\n",
      "Number of nodes in largest component: N/A (directed graph)\n",
      "Average Clustering Coefficient: 0.14147102442629086\n",
      "Transitivity/Global clustering coeff: 0.13006166877182554\n",
      "\n",
      "[INFO] Starting graph analytics\n",
      "[INFO] Graph is a PyTorch Geometric Data object, converting to NetworkX graph.\n",
      "\n",
      "----------Basic graph information-----------\n",
      "Type:  <class 'networkx.classes.digraph.DiGraph'>\n",
      "DiGraph with 19717 nodes and 88648 edges\n",
      "Number of nodes:  19717\n",
      "Number of edges:  88648\n",
      "Average node degree:  8.992037328193945\n",
      "Has isolated nodes:  0\n",
      "Has self loops:  0\n",
      "Is directed:  True\n",
      "Warning: Connected components and largest component stats not available for directed graphs.\n",
      "Error calculating Average Shortest Path (Largest Component): local variable 'largest_cc' referenced before assignment\n",
      "Error calculating Number of Connected Components: not implemented for directed type\n",
      "----------Graph extra statistics-----------\n",
      "Number of connected components: N/A (directed graph)\n",
      "Number of nodes in largest component: N/A (directed graph)\n",
      "Average Clustering Coefficient: 0.060175209437523615\n",
      "Transitivity/Global clustering coeff: 0.0537076280274887\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for data in list_of_data:\n",
    "    graph_vis.print_graph_info_cluster(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54afb6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_erdos_renyi_graphs(node_counts, avg_degree=10, seed=None):\n",
    "    \"\"\"\n",
    "    Creates Erdos-Renyi graphs with a given average degree.\n",
    "    Returns both networkx graphs and torch_geometric Data objects.\n",
    "    \"\"\"\n",
    "    graphs_nx = []\n",
    "    graphs_data = []\n",
    "    for n in node_counts:\n",
    "        p = avg_degree / (n - 1) if n > 1 else 0\n",
    "        G = nx.erdos_renyi_graph(n, p, seed=seed)\n",
    "        # Assign dummy y labels (all zeros)\n",
    "        nx.set_node_attributes(G, 0, 'y')\n",
    "        graphs_nx.append(G)\n",
    "\n",
    "        graph_data = utils.nx_to_pytorch_data_converter(G)\n",
    "        graph_data = utils.create_masks(graph_data)\n",
    "        graphs_data.append(graph_data)\n",
    "\n",
    "    return graphs_nx, graphs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72230656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting graph analytics\n",
      "\n",
      "----------Basic graph information-----------\n",
      "Type:  <class 'networkx.classes.graph.Graph'>\n",
      "Graph with 100 nodes and 482 edges\n",
      "Number of nodes:  100\n",
      "Number of edges:  482\n",
      "Average node degree:  9.64\n",
      "Has isolated nodes:  0\n",
      "Has self loops:  0\n",
      "Is directed:  False\n",
      "----------Graph extra statistics-----------\n",
      "Number of connected components: 1\n",
      "Number of nodes in largest component: 100\n",
      "Average Clustering Coefficient: 0.08894197469197461\n",
      "Transitivity/Global clustering coeff: 0.09407894736842105\n",
      "Average Shortest Path (Largest Component): 2.255757575757576\n",
      "Number of Connected Components: 1\n",
      "\n",
      "[INFO] Starting graph analytics\n",
      "\n",
      "----------Basic graph information-----------\n",
      "Type:  <class 'networkx.classes.graph.Graph'>\n",
      "Graph with 200 nodes and 949 edges\n",
      "Number of nodes:  200\n",
      "Number of edges:  949\n",
      "Average node degree:  9.49\n",
      "Has isolated nodes:  0\n",
      "Has self loops:  0\n",
      "Is directed:  False\n",
      "----------Graph extra statistics-----------\n",
      "Number of connected components: 1\n",
      "Number of nodes in largest component: 200\n",
      "Average Clustering Coefficient: 0.04689172755349223\n",
      "Transitivity/Global clustering coeff: 0.04609081597814954\n",
      "Average Shortest Path (Largest Component): 2.585175879396985\n",
      "Number of Connected Components: 1\n",
      "\n",
      "[INFO] Starting graph analytics\n",
      "\n",
      "----------Basic graph information-----------\n",
      "Type:  <class 'networkx.classes.graph.Graph'>\n",
      "Graph with 300 nodes and 1515 edges\n",
      "Number of nodes:  300\n",
      "Number of edges:  1515\n",
      "Average node degree:  10.1\n",
      "Has isolated nodes:  0\n",
      "Has self loops:  0\n",
      "Is directed:  False\n",
      "----------Graph extra statistics-----------\n",
      "Number of connected components: 1\n",
      "Number of nodes in largest component: 300\n",
      "Average Clustering Coefficient: 0.031223507213983693\n",
      "Transitivity/Global clustering coeff: 0.032179520926559624\n",
      "Average Shortest Path (Largest Component): 2.7079375696767003\n",
      "Number of Connected Components: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "er_graphs,er_data = create_erdos_renyi_graphs([100, 200, 300], avg_degree=10, seed=42)\n",
    "\n",
    "\n",
    "for graph in er_graphs:\n",
    "    graph_vis.print_graph_info_cluster(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a8e42f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066edcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with p=1_q=2 = {'embedding_dim': 128, 'walk_length': 70, 'context_size': 14, 'walks_per_node': 18, 'num_negative_samples': 1, 'sparse': True, 'p': 1, 'q': 2}\n",
      "Model initialization parameters provided as dictionary.\n",
      "Model initialized\n",
      "Starting training for 8 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 7.6409, Acc: 0.1700, Duration: 158.62s\n",
      "Dataset name: load_dataset_Cora\n",
      "    New best model saved with accuracy: 0.1700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Loss: 5.2049, Acc: 0.2160, Duration: 133.11s\n",
      "Dataset name: load_dataset_Cora\n",
      "    New best model saved with accuracy: 0.2160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Loss: 3.8519, Acc: 0.2700, Duration: 129.93s\n",
      "Dataset name: load_dataset_Cora\n",
      "    New best model saved with accuracy: 0.2700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Loss: 2.9278, Acc: 0.3340, Duration: 132.84s\n",
      "Dataset name: load_dataset_Cora\n",
      "    New best model saved with accuracy: 0.3340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Loss: 2.3002, Acc: 0.3740, Duration: 135.97s\n",
      "Dataset name: load_dataset_Cora\n",
      "    New best model saved with accuracy: 0.3740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Loss: 1.8728, Acc: 0.4140, Duration: 130.45s\n",
      "Dataset name: load_dataset_Cora\n",
      "    New best model saved with accuracy: 0.4140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_n2v\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_node2vecs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_of_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\csaba\\Documents\\Coding\\git_own\\thesis_coding\\train_n2v.py:50\u001b[0m, in \u001b[0;36mtrain_node2vecs\u001b[1;34m(data_list, num_training_epochs, parameter_dicts, device)\u001b[0m\n\u001b[0;32m     47\u001b[0m loader, optimizer \u001b[38;5;241m=\u001b[39m set_loader_and_optimizer(model)\n\u001b[0;32m     48\u001b[0m num_training_epochs \u001b[38;5;241m=\u001b[39m num_training_epochs \u001b[38;5;66;03m# Or 201, etc.\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m best_state, training_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_training_n2v\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_training_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./training_data/models/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Example save path\u001b[39;49;00m\n\u001b[0;32m     59\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\csaba\\Documents\\Coding\\git_own\\thesis_coding\\training.py:185\u001b[0m, in \u001b[0;36mmodel_training_n2v\u001b[1;34m(model, model_init_params, data, loader, optimizer, num_epochs, device, all_plots, model_save_path)\u001b[0m\n\u001b[0;32m    183\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    184\u001b[0m loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mloss(pos_rw\u001b[38;5;241m.\u001b[39mto(device), neg_rw\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m--> 185\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    187\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\csaba\\Documents\\Coding\\git_own\\thesis_coding\\.venv-thesis_coding-py3.10\\lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\csaba\\Documents\\Coding\\git_own\\thesis_coding\\.venv-thesis_coding-py3.10\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\csaba\\Documents\\Coding\\git_own\\thesis_coding\\.venv-thesis_coding-py3.10\\lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train_n2v.train_node2vecs(list_of_data, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694ab2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-thesis_coding-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
