{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33058ebf-433f-4df9-a2c5-1c016a2a1adc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Node2Vec algorithm\n",
    "\n",
    "Paper: https://arxiv.org/pdf/1607.00653\n",
    "\n",
    "## Abstract\n",
    "Here we propose node2vec, an algorithmic framework for learning continuous feature representations for nodes in networks. In\n",
    "node2vec, we learn a mapping of nodes to a low-dimensional space\n",
    "of features that maximizes the likelihood of preserving network\n",
    "neighborhoods of nodes. We define a flexible notion of a nodeâ€™s\n",
    "network neighborhood and design a biased random walk procedure,\n",
    "which efficiently explores diverse neighborhoods. Our algorithm\n",
    "generalizes prior work which is based on rigid notions of network\n",
    "neighborhoods, and we argue that the added flexibility in exploring\n",
    "neighborhoods is the key to learning richer representations\n",
    "\n",
    "## Actual work \n",
    "Our experiments focus on two common prediction tasks in networks: a multi-label classification task, where every node is assigned one or more class labels and a link prediction task, where we\n",
    "predict the existence of an edge given a pair of nodes. We contrast\n",
    "the performance of node2vec with state-of-the-art feature learning\n",
    "algorithms [24, 28]. We experiment with several real-world networks from diverse domains, such as social networks, information\n",
    "networks, as well as networks from systems biology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df5d7736-6b08-40d7-baf2-b0d7a6fa4c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c83a1d8-d296-4e64-abb7-df88f0308299",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m path \u001b[38;5;241m=\u001b[39m osp\u001b[38;5;241m.\u001b[39mjoin(osp\u001b[38;5;241m.\u001b[39mdirname(osp\u001b[38;5;241m.\u001b[39mrealpath(\u001b[38;5;18;43m__file__\u001b[39;49m)), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlanetoid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m Planetoid(path, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCora\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m data \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', 'Planetoid')\n",
    "dataset = Planetoid(path, name='Cora')\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ddb1b1-8a35-4cf9-9c84-50dc23d758d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = Node2Vec(\n",
    "    data.edge_index,\n",
    "    embedding_dim=128,\n",
    "    walk_length=20,\n",
    "    context_size=10,\n",
    "    walks_per_node=10,\n",
    "    num_negative_samples=1,\n",
    "    p=1.0,\n",
    "    q=1.0,\n",
    "    sparse=True,\n",
    ").to(device)\n",
    "\n",
    "num_workers = 4 if sys.platform == 'linux' else 0\n",
    "loader = model.loader(batch_size=128, shuffle=True, num_workers=num_workers)\n",
    "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb75afeb-e023-4b9d-aba2-d6ef7978d330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    z = model()\n",
    "    acc = model.test(\n",
    "        train_z=z[data.train_mask],\n",
    "        train_y=data.y[data.train_mask],\n",
    "        test_z=z[data.test_mask],\n",
    "        test_y=data.y[data.test_mask],\n",
    "        max_iter=150,\n",
    "    )\n",
    "    return acc\n",
    "\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    acc = test()\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Acc: {acc:.4f}')\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def plot_points(colors):\n",
    "    model.eval()\n",
    "    z = model().cpu().numpy()\n",
    "    z = TSNE(n_components=2).fit_transform(z)\n",
    "    y = data.y.cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for i in range(dataset.num_classes):\n",
    "        plt.scatter(z[y == i, 0], z[y == i, 1], s=20, color=colors[i])\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "colors = [\n",
    "    '#ffc0cb', '#bada55', '#008080', '#420420', '#7fe5f0', '#065535', '#ffd700'\n",
    "]\n",
    "plot_points(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56809025-d4b1-400d-a41e-fb39adb10604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import karateclub "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f90795-6b56-4971-ac55-2692a88281bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation Example: Node2vec in PyTorch\n",
    "# This example demonstrates a simple implementation of node2vec using PyTorch.\n",
    "\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Construct a Graph for Node2vec\n",
    "# --------------------------------------\n",
    "# Create a homogeneous graph using NetworkX\n",
    "G = nx.fast_gnp_random_graph(n=100, p=0.1)  # Random graph with 100 nodes\n",
    "\n",
    "# Define custom random walk function for node2vec\n",
    "# This function will generate sequences of nodes based on the random walk approach\n",
    "\n",
    "def generate_node2vec_walks(graph, num_walks, walk_length):\n",
    "    walks = []\n",
    "    nodes = list(graph.nodes())\n",
    "    for _ in range(num_walks):\n",
    "        for node in nodes:\n",
    "            walk = [node]\n",
    "            for _ in range(walk_length - 1):\n",
    "                neighbors = list(graph.neighbors(walk[-1]))\n",
    "                if neighbors:\n",
    "                    walk.append(random.choice(neighbors))\n",
    "                else:\n",
    "                    break\n",
    "            walks.append(walk)\n",
    "    return walks\n",
    "\n",
    "# Generate random walks for training\n",
    "num_walks = 10\n",
    "walk_length = 5\n",
    "generated_walks = generate_node2vec_walks(G, num_walks, walk_length)\n",
    "\n",
    "# Train Word2Vec model on generated walks (node2vec)\n",
    "walks = [list(map(str, walk)) for walk in generated_walks]\n",
    "node2vec_model = Word2Vec(walks, vector_size=128, window=5, min_count=0, sg=1, workers=4, epochs=10)\n",
    "\n",
    "# Step 2: Define Skip-gram Model in PyTorch\n",
    "# -----------------------------------------\n",
    "class SkipGramModel(nn.Module):\n",
    "    def __init__(self, num_nodes, embedding_dim):\n",
    "        super(SkipGramModel, self).__init__()\n",
    "        self.node_embeddings = nn.Embedding(num_nodes, embedding_dim)\n",
    "    \n",
    "    def forward(self, center_node, context_node):\n",
    "        center_embed = self.node_embeddings(center_node)\n",
    "        context_embed = self.node_embeddings(context_node)\n",
    "        score = torch.matmul(center_embed, context_embed.t())\n",
    "        return score\n",
    "\n",
    "# Step 3: Measuring Effectiveness\n",
    "# ----------------------------------\n",
    "# Define labels for nodes for a classification task (e.g., community detection or node classification)\n",
    "labels = np.random.randint(0, 2, size=100)  # Random binary labels for demonstration purposes\n",
    "\n",
    "# Split data into train and test sets\n",
    "X = [node2vec_model.wv[str(node)] for node in range(100)]\n",
    "y = labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a simple classifier (e.g., Logistic Regression) to evaluate embeddings\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate performance\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Node2Vec Embedding for Node 0:\")\n",
    "print(node2vec_model.wv['0'])\n",
    "print(f\"Accuracy of Node2Vec Embeddings: {accuracy}\")\n",
    "print(f\"F1 Score of Node2Vec Embeddings: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c888026-4e35-473d-91f7-f08a89ba5f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833f8972-c8f2-4edb-a923-b273ce28f2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687bd6b3-c639-497d-a532-2e81353b81e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f85376f-cb85-437b-ac32-facca3527668",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-thesis_coding-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
