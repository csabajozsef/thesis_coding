{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4018fbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install pecanpy if needed:\n",
    "# pip install pecanpya\n",
    "\n",
    "import networkx as nx\n",
    "import pecanpy\n",
    "from pecanpy.pecanpy import SparseOTF\n",
    "# from pecanpy import SparseOTF\n",
    "\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e74cdeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Cora as a NetworkX graph (assuming you have edge_index from PyG)\n",
    "# device = utils.set_seeds_and_device() \n",
    "# dataset,data = training.load_dataset('Cora', \"../training_data/datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3544eab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded from ./er_graphs\\er_graph_10.gpickle\n",
      "Successfully loaded Data from ./er_data\\er_graph_10.pt\n",
      "Successfully loaded from ./er_graphs\\er_graph_100.gpickle\n",
      "Successfully loaded Data from ./er_data\\er_graph_100.pt\n",
      "Successfully loaded from ./er_graphs\\er_graph_500.gpickle\n",
      "Successfully loaded Data from ./er_data\\er_graph_500.pt\n",
      "Successfully loaded from ./er_graphs\\er_graph_1000.gpickle\n",
      "Successfully loaded Data from ./er_data\\er_graph_1000.pt\n",
      "[10, 100, 500, 1000]\n",
      "[Data(edge_index=[2, 18], y=[10], num_nodes=10, train_mask=[10], test_mask=[10]), Data(edge_index=[2, 940], y=[100], num_nodes=100, train_mask=[100], test_mask=[100]), Data(edge_index=[2, 25150], y=[500], num_nodes=500, train_mask=[500], test_mask=[500]), Data(edge_index=[2, 100098], y=[1000], num_nodes=1000, train_mask=[1000], test_mask=[1000])]\n"
     ]
    }
   ],
   "source": [
    "def create_erdos_renyi_graphs(sizes, p=0.1, seed=None, save_dir_graphs=\"./er_graphs\", save_dir_data=\"./er_data\"):\n",
    "    os.makedirs(save_dir_graphs, exist_ok=True)\n",
    "    os.makedirs(save_dir_data, exist_ok=True)\n",
    "    graphs_nx = []\n",
    "    graphs_data = []\n",
    "\n",
    "    for n in sizes:\n",
    "        graph_path = os.path.join(save_dir_graphs, f\"er_graph_{n}.gpickle\")\n",
    "        data_path = os.path.join(save_dir_data, f\"er_graph_{n}.pt\")\n",
    "\n",
    "        # Load or create graph\n",
    "        if os.path.exists(graph_path):\n",
    "            with open(graph_path, \"rb\") as f:\n",
    "                G = pickle.load(f)\n",
    "            print(f\"Successfully loaded from {graph_path}\")\n",
    "        else:\n",
    "            G = nx.erdos_renyi_graph(n=n, p=p, seed=seed)\n",
    "            G = utils.add_louvain_community_labels(G)\n",
    "            with open(graph_path, \"wb\") as f:\n",
    "                pickle.dump(G, f)\n",
    "            print(f\"Saved new graph to {graph_path}\")\n",
    "\n",
    "        graphs_nx.append(G)\n",
    "\n",
    "        # Load or create Data object\n",
    "        if os.path.exists(data_path):\n",
    "            data = torch.load(data_path, weights_only=False)\n",
    "            print(f\"Successfully loaded Data from {data_path}\")\n",
    "        else:\n",
    "            data = from_networkx(G)\n",
    "            data = utils.create_masks(data)\n",
    "            torch.save(data, data_path)\n",
    "            print(f\"Saved new Data to {data_path}\")\n",
    "\n",
    "        graphs_data.append(data)\n",
    "\n",
    "    return graphs_nx, graphs_data\n",
    "\n",
    "# Usage\n",
    "sizes = [10, 100,500, 1000]#,1000,5000,10000]\n",
    "graphs_nx, graphs_data = create_erdos_renyi_graphs(sizes, p=0.1)\n",
    "print([len(g.nodes) for g in graphs_nx])\n",
    "print(graphs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "749915cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved graph_0.edg\n",
      "Saved graph_1.edg\n",
      "Saved graph_2.edg\n",
      "Saved graph_3.edg\n"
     ]
    }
   ],
   "source": [
    "for idx, data in enumerate(graphs_data):\n",
    "    # Convert PyG data to NetworkX graph\n",
    "    G = nx.Graph()\n",
    "    edge_index = data.edge_index.cpu().numpy()\n",
    "    edges = list(zip(edge_index[0], edge_index[1]))\n",
    "    G.add_edges_from(edges)\n",
    "\n",
    "    # Save as .edg file (tab-separated, no header)\n",
    "    edgelist_path = f\"graph_{idx}.edg\"\n",
    "    nx.write_edgelist(G, edgelist_path, data=False, delimiter='\\t')\n",
    "    print(f\"Saved {edgelist_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "220d3819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# load graph object using SparseOTF mode\n",
    "g = SparseOTF(p=1, q=1, workers=1, verbose=False)\n",
    "g.read_edg(\"graph_3.edg\", weighted=False, directed=False)\n",
    "# generate random walks\n",
    "walks = g.simulate_walks(num_walks=10, walk_length=80)\n",
    "# use random walks to train embeddings\n",
    "w2v_model = Word2Vec(walks, vector_size=8, window=3, min_count=0, sg=1, workers=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4424d162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-pecanpy-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
