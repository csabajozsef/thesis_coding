{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "56b4ac1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Random seed set to: 42\n",
      "p_values: [1, 2]\n",
      "q_values: [1, 2]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import training\n",
    "importlib.reload(training)\n",
    "import graph_vis\n",
    "importlib.reload(graph_vis)\n",
    "import graph_creation\n",
    "importlib.reload(graph_creation)\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "import train_n2v\n",
    "importlib.reload(train_n2v)\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch_geometric.utils import to_networkx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b9720e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cora,data_cora = training.load_dataset('Cora', \"../training_data/datasets\")\n",
    "dataset_citeseer,data_citeseer = training.load_dataset('Citeseer', \"../training_data/datasets\")\n",
    "dataset_pubmed,data_pubmed = training.load_dataset('Pubmed', \"../training_data/datasets\")\n",
    "\n",
    "list_of_datasets = [dataset_cora, dataset_citeseer, dataset_pubmed]\n",
    "list_of_data = [data_cora, data_citeseer, data_pubmed]\n",
    "\n",
    "\n",
    "# graph_vis.print_graph_info_cluster(data_cora)\n",
    "# graph_vis.pyg_graph_data_visualizer(data_cora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "20e55ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyg_data_to_dataframe(data):\n",
    "    \"\"\"\n",
    "    Converts a PyG data object to a pandas DataFrame.\n",
    "    Each row is a node, columns are features (and label if present).\n",
    "    \"\"\"\n",
    "    # Node features\n",
    "    x = data.x.cpu().numpy() if isinstance(data.x, torch.Tensor) else data.x\n",
    "    df = pd.DataFrame(x, columns=[f'feat_{i}' for i in range(x.shape[1])])\n",
    "    \n",
    "    # Node labels (if present)\n",
    "    if hasattr(data, 'y') and data.y is not None:\n",
    "        df['label'] = data.y.cpu().numpy()\n",
    "    \n",
    "    # Node indices as index\n",
    "    df.index.name = 'node_id'\n",
    "    return df\n",
    "\n",
    "df = pyg_data_to_dataframe(data_cora)\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4a6356f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         feat_0  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  \\\n",
      "node_id                                                                   \n",
      "0           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "1           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "3           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "4           0.0     0.0     0.0     1.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "         feat_8  feat_9  ...  feat_1429  feat_1430  feat_1431  feat_1432  \\\n",
      "node_id                  ...                                               \n",
      "0           0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
      "1           0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
      "2           0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
      "3           0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
      "4           0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
      "\n",
      "         label  clustering_coef_m  degree_centrality_m  eigen_centrality_m  \\\n",
      "node_id                                                                      \n",
      "0            3           0.333333             0.001108        9.057668e-05   \n",
      "1            4           0.000000             0.001108        9.464577e-05   \n",
      "2            4           0.000000             0.001847        1.346099e-03   \n",
      "3            0           0.000000             0.000369        7.402930e-33   \n",
      "4            3           0.700000             0.001847        4.627332e-03   \n",
      "\n",
      "         degree_m  neighbor_labels_avg_m  \n",
      "node_id                                   \n",
      "0               3                    3.0  \n",
      "1               3                    4.0  \n",
      "2               5                    3.4  \n",
      "3               1                    0.0  \n",
      "4               5                    2.6  \n",
      "\n",
      "[5 rows x 1439 columns]\n"
     ]
    }
   ],
   "source": [
    "def add_new_features(\n",
    "    data_cora, \n",
    "    df, \n",
    "    clustering_coeff: bool = True, \n",
    "    node_centrality: bool = True,\n",
    "    node_centrality_eigen: bool = True,\n",
    "    node_centrality_betweenness: bool = False, \n",
    "    node_centrality_closeness: bool = False, \n",
    "    node_degree: bool = True,\n",
    "    neighbor_label_avg: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Adds new features to the DataFrame:\n",
    "    - clustering_coef_m: clustering coefficient of each node (optional)\n",
    "    - degree_centrality_m: degree centrality of each node (optional)\n",
    "    - degree_m: degree of each node (optional)\n",
    "    - neighbor_labels_avg: average of neighbor labels (optional)\n",
    "    \"\"\"\n",
    "\n",
    "    # node_centrality_betweenness = True\n",
    "\n",
    "    G = to_networkx(data_cora, to_undirected=True)\n",
    "    \n",
    "    if clustering_coeff:\n",
    "        clustering_dict = nx.clustering(G)\n",
    "        df['clustering_coef_m'] = pd.Series(clustering_dict)\n",
    "\n",
    "    if node_centrality:\n",
    "        centrality_dict = nx.degree_centrality(G)\n",
    "        df['degree_centrality_m'] = pd.Series(centrality_dict)\n",
    "    \n",
    "    if node_centrality_eigen:\n",
    "        eigen_centrality_dict = nx.eigenvector_centrality(G, max_iter=1000)\n",
    "        df['eigen_centrality_m'] = pd.Series(eigen_centrality_dict)\n",
    "\n",
    "    if node_centrality_betweenness:\n",
    "        betweenness_dict = nx.betweenness_centrality(G, normalized=True)\n",
    "        df['betweenness_centrality_m'] = pd.Series(betweenness_dict)\n",
    "\n",
    "    if node_centrality_closeness:\n",
    "        closeness_dict = nx.closeness_centrality(G)\n",
    "        df['closeness_centrality_m'] = pd.Series(closeness_dict)    \n",
    "\n",
    "    if node_degree:\n",
    "        degree_dict = dict(G.degree())\n",
    "        df['degree_m'] = pd.Series(degree_dict)\n",
    "    \n",
    "    if neighbor_label_avg:\n",
    "        # Get labels as a Series for fast lookup\n",
    "        label_series = df['label']\n",
    "        neighbor_label_avg_dict = {}\n",
    "        for node in G.nodes():\n",
    "            neighbors = list(G.neighbors(node))\n",
    "            if neighbors:\n",
    "                neighbor_labels = label_series.loc[neighbors].values\n",
    "                neighbor_label_avg_dict[node] = neighbor_labels.mean()\n",
    "            else:\n",
    "                neighbor_label_avg_dict[node] = float('nan')  # or 0, or the node's own label\n",
    "        df['neighbor_labels_avg_m'] = pd.Series(neighbor_label_avg_dict)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "df = add_new_features(data_cora, df, clustering_coeff=True, node_centrality=True, node_degree=True, neighbor_label_avg=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b414cf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['neighbor_labels_avg_m']\n",
      "Splitting data into train and test sets...\n",
      "\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Test accuracy: 0.6052\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.63      0.58        70\n",
      "           1       0.00      0.00      0.00        43\n",
      "           2       0.22      0.10      0.13        84\n",
      "           3       0.54      0.90      0.67       164\n",
      "           4       0.85      0.75      0.80        85\n",
      "           5       0.81      0.72      0.76        60\n",
      "           6       0.92      0.61      0.73        36\n",
      "\n",
      "    accuracy                           0.61       542\n",
      "   macro avg       0.55      0.53      0.53       542\n",
      "weighted avg       0.55      0.61      0.56       542\n",
      "\n",
      "\n",
      "Training SVM...\n",
      "SVM Test accuracy: 0.7472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.47      0.60        70\n",
      "           1       0.57      0.77      0.65        43\n",
      "           2       0.66      0.92      0.77        84\n",
      "           3       0.81      0.81      0.81       164\n",
      "           4       0.74      0.80      0.77        85\n",
      "           5       0.82      0.68      0.75        60\n",
      "           6       0.95      0.56      0.70        36\n",
      "\n",
      "    accuracy                           0.75       542\n",
      "   macro avg       0.77      0.72      0.72       542\n",
      "weighted avg       0.77      0.75      0.74       542\n",
      "\n",
      "\n",
      "Training KNN...\n",
      "KNN Test accuracy: 0.7509\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.57      0.58        70\n",
      "           1       0.61      0.72      0.66        43\n",
      "           2       0.78      0.85      0.81        84\n",
      "           3       0.79      0.82      0.80       164\n",
      "           4       0.85      0.72      0.78        85\n",
      "           5       0.72      0.78      0.75        60\n",
      "           6       0.85      0.64      0.73        36\n",
      "\n",
      "    accuracy                           0.75       542\n",
      "   macro avg       0.74      0.73      0.73       542\n",
      "weighted avg       0.76      0.75      0.75       542\n",
      "\n",
      "\n",
      "Training Decision Tree...\n",
      "Decision Tree Test accuracy: 0.7546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.59      0.59        70\n",
      "           1       0.72      0.65      0.68        43\n",
      "           2       0.70      0.90      0.79        84\n",
      "           3       0.80      0.81      0.80       164\n",
      "           4       0.85      0.74      0.79        85\n",
      "           5       0.79      0.75      0.77        60\n",
      "           6       0.82      0.64      0.72        36\n",
      "\n",
      "    accuracy                           0.75       542\n",
      "   macro avg       0.75      0.73      0.74       542\n",
      "weighted avg       0.76      0.75      0.75       542\n",
      "\n",
      "\n",
      "Training Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\csaba\\Documents\\Coding\\git_own\\thesis_coding\\.venv-thesis_coding-py3.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\csaba\\Documents\\Coding\\git_own\\thesis_coding\\.venv-thesis_coding-py3.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\csaba\\Documents\\Coding\\git_own\\thesis_coding\\.venv-thesis_coding-py3.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test accuracy: 0.7546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.56      0.59        70\n",
      "           1       0.74      0.65      0.69        43\n",
      "           2       0.72      0.88      0.79        84\n",
      "           3       0.77      0.84      0.80       164\n",
      "           4       0.86      0.73      0.79        85\n",
      "           5       0.78      0.77      0.77        60\n",
      "           6       0.79      0.64      0.71        36\n",
      "\n",
      "    accuracy                           0.75       542\n",
      "   macro avg       0.75      0.72      0.73       542\n",
      "weighted avg       0.76      0.75      0.75       542\n",
      "\n",
      "\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Test accuracy: 0.7638\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.51      0.62        70\n",
      "           1       0.61      0.77      0.68        43\n",
      "           2       0.73      0.88      0.80        84\n",
      "           3       0.77      0.85      0.81       164\n",
      "           4       0.85      0.74      0.79        85\n",
      "           5       0.79      0.75      0.77        60\n",
      "           6       0.79      0.64      0.71        36\n",
      "\n",
      "    accuracy                           0.76       542\n",
      "   macro avg       0.76      0.74      0.74       542\n",
      "weighted avg       0.77      0.76      0.76       542\n",
      "\n",
      "\n",
      "Training MLP...\n",
      "MLP Test accuracy: 0.7638\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.51      0.64        70\n",
      "           1       0.60      0.77      0.67        43\n",
      "           2       0.70      0.89      0.79        84\n",
      "           3       0.79      0.84      0.82       164\n",
      "           4       0.78      0.80      0.79        85\n",
      "           5       0.81      0.72      0.76        60\n",
      "           6       0.91      0.58      0.71        36\n",
      "\n",
      "    accuracy                           0.76       542\n",
      "   macro avg       0.78      0.73      0.74       542\n",
      "weighted avg       0.78      0.76      0.76       542\n",
      "\n",
      "\n",
      "Summary of test accuracies:\n",
      "Logistic Regression: 0.6052\n",
      "SVM: 0.7472\n",
      "KNN: 0.7509\n",
      "Decision Tree: 0.7546\n",
      "Random Forest: 0.7546\n",
      "Gradient Boosting: 0.7638\n",
      "MLP: 0.7638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\csaba\\Documents\\Coding\\git_own\\thesis_coding\\.venv-thesis_coding-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Features and labels\n",
    "X = df.drop(columns=['label'], inplace=False)\n",
    "X = X[['neighbor_labels_avg_m']]\n",
    "# X = X[[col for col in X.columns if not col.endswith('_m') or col != 'neighbor_labels_avg_m']]\n",
    "# X = X[[col for col in X.columns if not (col.endswith('_m') and col != 'neighbor_labels_avg_m')]]\n",
    "# X.drop(columns=['neighbor_labels_avg_m'], inplace=True)\n",
    "# X.drop(columns=['degree_centrality_m'], inplace=True)\n",
    "# X.drop(columns=['eigen_centrality_m'], inplace=True)\n",
    "# X.drop(columns=['betweenness_centrality_m'], inplace=True)\n",
    "y = df['label']\n",
    "print(len(X.columns.tolist()),X.columns.tolist()[-7:])\n",
    "\n",
    "print(\"Splitting data into train and test sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"SVM\": SVC(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"MLP\": MLPClassifier(max_iter=500)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        print(f\"{name} Test accuracy: {acc:.4f}\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        results[name] = acc\n",
    "    except Exception as e:\n",
    "        print(f\"{name} failed: {e}\")\n",
    "\n",
    "print(\"\\nSummary of test accuracies:\")\n",
    "for name, acc in results.items():\n",
    "    print(f\"{name}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "57ad5413",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MLPClassifier' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[152], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m importances \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_importances_\u001b[49m\n\u001b[0;32m      2\u001b[0m importances_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m'\u001b[39m: X\u001b[38;5;241m.\u001b[39mcolumns,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimportance\u001b[39m\u001b[38;5;124m'\u001b[39m: importances\n\u001b[0;32m      5\u001b[0m })\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimportance\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(importances_df)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MLPClassifier' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "importances = model.feature_importances_\n",
    "importances_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(importances_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-thesis_coding-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
