{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56b4ac1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Random seed set to: 42\n",
      "p_values: [1, 2]\n",
      "q_values: [1, 2]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import training\n",
    "importlib.reload(training)\n",
    "import graph_vis\n",
    "importlib.reload(graph_vis)\n",
    "import graph_creation\n",
    "importlib.reload(graph_creation)\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "import train_n2v\n",
    "importlib.reload(train_n2v)\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9720e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting graph analytics\n",
      "[INFO] Graph is a PyTorch Geometric Data object, converting to NetworkX graph.\n",
      "\n",
      "----------Basic graph information-----------\n",
      "Type:  <class 'networkx.classes.digraph.DiGraph'>\n",
      "DiGraph with 2708 nodes and 10556 edges\n",
      "Number of nodes:  2708\n",
      "Number of edges:  10556\n",
      "Average node degree:  7.796159527326441\n",
      "Has isolated nodes:  0\n",
      "Has self loops:  0\n",
      "Is directed:  True\n",
      "Warning: Connected components and largest component stats not available for directed graphs.\n",
      "Error calculating Average Shortest Path (Largest Component): local variable 'largest_cc' referenced before assignment\n",
      "Error calculating Number of Connected Components: not implemented for directed type\n",
      "----------Graph extra statistics-----------\n",
      "Number of connected components: N/A (directed graph)\n",
      "Number of nodes in largest component: N/A (directed graph)\n",
      "Average Clustering Coefficient: 0.24067329850193728\n",
      "Transitivity/Global clustering coeff: 0.09349725626661058\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_cora,data_cora = training.load_dataset('Cora')\n",
    "dataset_citeseer,data_citeseer = training.load_dataset('Citeseer')\n",
    "dataset_pubmed,data_pubmed = training.load_dataset('Pubmed')\n",
    "\n",
    "list_of_datasets = [dataset_cora, dataset_citeseer, dataset_pubmed]\n",
    "list_of_data = [data_cora, data_citeseer, data_pubmed]\n",
    "\n",
    "\n",
    "graph_vis.print_graph_info_cluster(data_cora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20e55ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyg_data_to_dataframe(data):\n",
    "    \"\"\"\n",
    "    Converts a PyG data object to a pandas DataFrame.\n",
    "    Each row is a node, columns are features (and label if present).\n",
    "    \"\"\"\n",
    "    # Node features\n",
    "    x = data.x.cpu().numpy() if isinstance(data.x, torch.Tensor) else data.x\n",
    "    df = pd.DataFrame(x, columns=[f'feat_{i}' for i in range(x.shape[1])])\n",
    "    \n",
    "    # Node labels (if present)\n",
    "    if hasattr(data, 'y') and data.y is not None:\n",
    "        df['label'] = data.y.cpu().numpy()\n",
    "    \n",
    "    # Node indices as index\n",
    "    df.index.name = 'node_id'\n",
    "    return df\n",
    "\n",
    "df = pyg_data_to_dataframe(data_cora)\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f53b8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feat_0       0.0\n",
       "feat_1       0.0\n",
       "feat_2       0.0\n",
       "feat_3       0.0\n",
       "feat_4       0.0\n",
       "            ... \n",
       "feat_1429    0.0\n",
       "feat_1430    0.0\n",
       "feat_1431    0.0\n",
       "feat_1432    0.0\n",
       "label        3.0\n",
       "Name: 0, Length: 1434, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95d4ffac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         feat_0  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  \\\n",
      "node_id                                                                   \n",
      "0           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "1           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "3           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "4           0.0     0.0     0.0     1.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "         feat_8  feat_9  ...  feat_1426  feat_1427  feat_1428  feat_1429  \\\n",
      "node_id                  ...                                               \n",
      "0           0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
      "1           0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
      "2           0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
      "3           0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
      "4           0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
      "\n",
      "         feat_1430  feat_1431  feat_1432  label  clustering_coef  \\\n",
      "node_id                                                            \n",
      "0              0.0        0.0        0.0      3         0.333333   \n",
      "1              0.0        0.0        0.0      4         0.000000   \n",
      "2              0.0        0.0        0.0      4         0.000000   \n",
      "3              0.0        0.0        0.0      0         0.000000   \n",
      "4              0.0        0.0        0.0      3         0.700000   \n",
      "\n",
      "         degree_centrality  \n",
      "node_id                     \n",
      "0                 0.001108  \n",
      "1                 0.001108  \n",
      "2                 0.001847  \n",
      "3                 0.000369  \n",
      "4                 0.001847  \n",
      "\n",
      "[5 rows x 1436 columns]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "def add_new_features(\n",
    "    data_cora, \n",
    "    df, \n",
    "    clustering_coeff: bool = True, \n",
    "    node_centrality: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Adds new features to the DataFrame:\n",
    "    - clustering_coef: clustering coefficient of each node (optional)\n",
    "    - node_centrality: degree centrality of each node (optional)\n",
    "    \"\"\"\n",
    "    G = to_networkx(data_cora, to_undirected=True)\n",
    "    \n",
    "    if clustering_coeff:\n",
    "        clustering_dict = nx.clustering(G)\n",
    "        df['clustering_coef'] = pd.Series(clustering_dict)\n",
    "    \n",
    "    if node_centrality:\n",
    "        centrality_dict = nx.degree_centrality(G)\n",
    "        df['degree_centrality'] = pd.Series(centrality_dict)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "df = add_new_features(data_cora, df, clustering_coeff=True, node_centrality=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8082a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into train and test sets...\n",
      "Starting hyperparameter tuning with GridSearchCV...\n",
      "Best parameters found: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Training best Random Forest model on training data...\n",
      "Predicting on test set...\n",
      "Test accuracy: 0.7749\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.57      0.60        70\n",
      "           1       0.91      0.70      0.79        43\n",
      "           2       0.88      0.87      0.87        84\n",
      "           3       0.72      0.88      0.79       164\n",
      "           4       0.82      0.80      0.81        85\n",
      "           5       0.80      0.73      0.77        60\n",
      "           6       0.91      0.56      0.69        36\n",
      "\n",
      "    accuracy                           0.77       542\n",
      "   macro avg       0.81      0.73      0.76       542\n",
      "weighted avg       0.78      0.77      0.77       542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Features and labels\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "\n",
    "print(\"Splitting data into train and test sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Starting hyperparameter tuning with GridSearchCV...\")\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found:\", grid.best_params_)\n",
    "\n",
    "print(\"Training best Random Forest model on training data...\")\n",
    "best_rf = grid.best_estimator_\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Predicting on test set...\")\n",
    "y_pred = best_rf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test accuracy: {acc:.4f}\")\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cea67b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        feature    importance\n",
      "495    feat_495  4.645216e-02\n",
      "581    feat_581  2.541807e-02\n",
      "774    feat_774  2.411607e-02\n",
      "19      feat_19  2.198482e-02\n",
      "1254  feat_1254  1.728652e-02\n",
      "...         ...           ...\n",
      "950    feat_950  2.957123e-06\n",
      "977    feat_977  1.009714e-07\n",
      "742    feat_742  0.000000e+00\n",
      "444    feat_444  0.000000e+00\n",
      "1323  feat_1323  0.000000e+00\n",
      "\n",
      "[1435 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "importances = best_rf.feature_importances_\n",
    "importances_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(importances_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-thesis_coding-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
