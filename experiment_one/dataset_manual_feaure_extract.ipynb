{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56b4ac1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Random seed set to: 42\n",
      "p_values: [1, 2]\n",
      "q_values: [1, 2]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import training\n",
    "importlib.reload(training)\n",
    "import graph_vis\n",
    "importlib.reload(graph_vis)\n",
    "import graph_creation\n",
    "importlib.reload(graph_creation)\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "import train_n2v\n",
    "importlib.reload(train_n2v)\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from torch_geometric.utils import to_networkx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b9720e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting graph analytics\n",
      "[INFO] Graph is a PyTorch Geometric Data object, converting to NetworkX graph.\n",
      "\n",
      "----------Basic graph information-----------\n",
      "Type:  <class 'networkx.classes.digraph.DiGraph'>\n",
      "DiGraph with 2708 nodes and 10556 edges\n",
      "Number of nodes:  2708\n",
      "Number of edges:  10556\n",
      "Average node degree:  7.796159527326441\n",
      "Has isolated nodes:  0\n",
      "Has self loops:  0\n",
      "Is directed:  True\n",
      "Warning: Connected components and largest component stats not available for directed graphs.\n",
      "Error calculating Average Shortest Path (Largest Component): local variable 'largest_cc' referenced before assignment\n",
      "Error calculating Number of Connected Components: not implemented for directed type\n",
      "----------Graph extra statistics-----------\n",
      "Number of connected components: N/A (directed graph)\n",
      "Number of nodes in largest component: N/A (directed graph)\n",
      "Average Clustering Coefficient: 0.24067329850193728\n",
      "Transitivity/Global clustering coeff: 0.09349725626661058\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_cora,data_cora = training.load_dataset('Cora')\n",
    "dataset_citeseer,data_citeseer = training.load_dataset('Citeseer')\n",
    "dataset_pubmed,data_pubmed = training.load_dataset('Pubmed')\n",
    "\n",
    "list_of_datasets = [dataset_cora, dataset_citeseer, dataset_pubmed]\n",
    "list_of_data = [data_cora, data_citeseer, data_pubmed]\n",
    "\n",
    "\n",
    "graph_vis.print_graph_info_cluster(data_cora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "20e55ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyg_data_to_dataframe(data):\n",
    "    \"\"\"\n",
    "    Converts a PyG data object to a pandas DataFrame.\n",
    "    Each row is a node, columns are features (and label if present).\n",
    "    \"\"\"\n",
    "    # Node features\n",
    "    x = data.x.cpu().numpy() if isinstance(data.x, torch.Tensor) else data.x\n",
    "    df = pd.DataFrame(x, columns=[f'feat_{i}' for i in range(x.shape[1])])\n",
    "    \n",
    "    # Node labels (if present)\n",
    "    if hasattr(data, 'y') and data.y is not None:\n",
    "        df['label'] = data.y.cpu().numpy()\n",
    "    \n",
    "    # Node indices as index\n",
    "    df.index.name = 'node_id'\n",
    "    return df\n",
    "\n",
    "df = pyg_data_to_dataframe(data_cora)\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6f53b8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feat_0       0.0\n",
       "feat_1       0.0\n",
       "feat_2       0.0\n",
       "feat_3       0.0\n",
       "feat_4       0.0\n",
       "            ... \n",
       "feat_1429    0.0\n",
       "feat_1430    0.0\n",
       "feat_1431    0.0\n",
       "feat_1432    0.0\n",
       "label        3.0\n",
       "Name: 0, Length: 1434, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a6356f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         feat_0  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  \\\n",
      "node_id                                                                   \n",
      "0           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "1           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "3           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "4           0.0     0.0     0.0     1.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "         feat_8  feat_9  ...  feat_1428  feat_1429  feat_1430  feat_1431  \\\n",
      "node_id                  ...                                               \n",
      "0           0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
      "1           0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
      "2           0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
      "3           0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
      "4           0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
      "\n",
      "         feat_1432  label  clustering_coef_m  degree_centrality_m  degree_m  \\\n",
      "node_id                                                                       \n",
      "0              0.0      3           0.333333             0.001108         3   \n",
      "1              0.0      4           0.000000             0.001108         3   \n",
      "2              0.0      4           0.000000             0.001847         5   \n",
      "3              0.0      0           0.000000             0.000369         1   \n",
      "4              0.0      3           0.700000             0.001847         5   \n",
      "\n",
      "         neighbor_labels_avg_m  \n",
      "node_id                         \n",
      "0                          3.0  \n",
      "1                          4.0  \n",
      "2                          3.4  \n",
      "3                          0.0  \n",
      "4                          2.6  \n",
      "\n",
      "[5 rows x 1438 columns]\n"
     ]
    }
   ],
   "source": [
    "def add_new_features(\n",
    "    data_cora, \n",
    "    df, \n",
    "    clustering_coeff: bool = True, \n",
    "    node_centrality: bool = True,\n",
    "    node_degree: bool = True,\n",
    "    neighbor_label_avg: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Adds new features to the DataFrame:\n",
    "    - clustering_coef_m: clustering coefficient of each node (optional)\n",
    "    - degree_centrality_m: degree centrality of each node (optional)\n",
    "    - degree_m: degree of each node (optional)\n",
    "    - neighbor_labels_avg: average of neighbor labels (optional)\n",
    "    \"\"\"\n",
    "    G = to_networkx(data_cora, to_undirected=True)\n",
    "    \n",
    "    if clustering_coeff:\n",
    "        clustering_dict = nx.clustering(G)\n",
    "        df['clustering_coef_m'] = pd.Series(clustering_dict)\n",
    "    \n",
    "    if node_centrality:\n",
    "        centrality_dict = nx.degree_centrality(G)\n",
    "        df['degree_centrality_m'] = pd.Series(centrality_dict)\n",
    "    \n",
    "    if node_degree:\n",
    "        degree_dict = dict(G.degree())\n",
    "        df['degree_m'] = pd.Series(degree_dict)\n",
    "    \n",
    "    if neighbor_label_avg:\n",
    "        # Get labels as a Series for fast lookup\n",
    "        label_series = df['label']\n",
    "        neighbor_label_avg_dict = {}\n",
    "        for node in G.nodes():\n",
    "            neighbors = list(G.neighbors(node))\n",
    "            if neighbors:\n",
    "                neighbor_labels = label_series.loc[neighbors].values\n",
    "                neighbor_label_avg_dict[node] = neighbor_labels.mean()\n",
    "            else:\n",
    "                neighbor_label_avg_dict[node] = float('nan')  # or 0, or the node's own label\n",
    "        df['neighbor_labels_avg_m'] = pd.Series(neighbor_label_avg_dict)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "df = add_new_features(data_cora, df, clustering_coeff=True, node_centrality=True, node_degree=True, neighbor_label_avg=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea2f6bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\csaba\\AppData\\Local\\Temp\\ipykernel_30260\\1275890570.py:44: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvUAAAG6CAYAAACIpLmpAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAYqNJREFUeJzt3XlclOX+//H3zLCLiCK4lIKIu2JupLmvlGJamZmeXNos07LNrH7ZITWOlVpqqWUn9Bw7R22RspNbaipWpga5ormf1MQFFRGFmfv3h1/mNII6wLAMvJ6PB4/inuu+7uueGcY3H677uk2GYRgCAAAA4LbMJT0AAAAAAIVDqAcAAADcHKEeAAAAcHOEegAAAMDNEeoBAAAAN0eoBwAAANwcoR4AAABwc4R6AAAAwM0R6gEAAAA3R6gvo4YPH66wsLCSHkaJCAsL0/Dhw0t6GOVOly5d1KVLl5u2c9fXx2Qy6a9//WuB9x09evRN2/31r3+VyWTSqVOnCnSc4pSenq6QkBAtXLiwSPpft26dTCaT1q1bVyT9F5Qz799Dhw7JZDLpnXfeKdKxxMfHy2Qy6dChQ/net0uXLmratKlLx3Ptc7N8+XL5+/srNTXVpccBkDdCfSHlfKjmfHl4eOiWW27R8OHD9fvvv5f08FBINptN8fHxuvvuu1WrVi1VqFBBTZs21aRJk5SZmZnnPn/88YdGjhypW265RT4+PgoLC9Mjjzzi0CYlJUXPPvus7rjjDvn4+NzwH+b09HSNHTtWt956q7y9vdWoUSPNnj3b1adaYnbt2qW//vWvBQomKDnvvfeeKlasqEGDBpX0UFBK3XnnnYqIiFBcXFxJDwUoFzxKegBlxRtvvKE6deooMzNTP/74o+Lj47Vx40bt2LFDPj4+JT08FFBGRoZGjBihtm3b6oknnlBISIh++OEHvf766/ruu++0Zs0amUwme/ujR4+qffv2kqQnnnhCt9xyi44dO6bNmzc79PvDDz9oxowZaty4sRo1aqSkpKQ8j2+1WhUdHa0tW7boqaeeUr169bRixQqNGjVKZ8+e1SuvvFJk515UUlJSZDb/r56wa9cuxcbGqkuXLqX6r0uXLl2ShwcfmZKUlZWl9957T88++6wsFktJDwel2MiRI/XCCy8oNjZWFStWLOnhAGUa/0K5yF133aXWrVtLkh599FFVrVpVU6ZM0VdffaWBAweW8OhQUF5eXkpMTNQdd9xh3/bYY48pLCzMHux79Ohhf2zkyJHy8PDQzz//rKCgoOv2e/fddystLU0VK1bUO++8c91Q/8UXX2jTpk36+OOP9fDDD0uSnnzySQ0YMEATJ07Uo48+qpCQENecbDHx9vYu6SEUSFn55dwwDGVmZsrX17fAfSxbtkypqalu9dl28eJFVahQoaSHUe7cd999GjNmjJYsWWL/DANQNJh+U0Q6duwoSdq/f79925UrVzRhwgS1atVKlSpVUoUKFdSxY0etXbvWYd8/z8f88MMPVbduXXl7e6tNmzb6+eefcx1r6dKlatq0qXx8fNS0aVN9+eWXeY7p4sWLev7551WrVi15e3urQYMGeuedd2QYhkO7nPm/S5YsUePGjeXr66t27dpp+/btkqS5c+cqIiJCPj4+6tKli1PTJnLmCv/2228aPny4AgMDValSJY0YMUIZGRkObbOzszVx4kT7eYeFhemVV17R5cuXHdoZhqFJkybp1ltvlZ+fn7p27aqdO3fmefy0tDSNHTvWfu4RERGaMmWKbDbbDcft5eXlEOhz3HPPPZKk3bt327ft2bNH3377rV588UUFBQUpMzNTWVlZefZbpUoVp6pWGzZskKRcUxwGDRqkzMxMJSQk3HD/M2fO6IUXXlCzZs3k7++vgIAA3XXXXUpOTnZolzN/efHixZo8ebJuvfVW+fj4qHv37vrtt99y9ZvzvvT19VVUVJR9nM7487zb+Ph43X///ZKkrl272qex5cyj3rJli6Kjo1W1alX5+vqqTp06TgWDsLAwxcTEaOPGjYqKipKPj4/Cw8O1YMGCXG2dfW/kNad+3bp1at26tXx8fFS3bl3NnTvX/l7PS87Pqre3t5o0aaLly5fn2e7UqVMaOHCgAgICFBQUpGeeeSbXdC9nf05ynosVK1aodevW8vX11dy5cyVJq1atUocOHRQYGCh/f381aNDAqb/+LF26VGFhYapbt26ux/bs2aOBAwcqODhYvr6+atCggV599VWHNr/88ovuuusuBQQEyN/fX927d9ePP/540+NK0pIlS9SqVSv5+vqqatWq+stf/pJrquPw4cPl7++v/fv3q3fv3qpYsaKGDBki6eqUunfffVdNmjSRj4+PqlWrppEjR+rs2bMOfeTn8+VGpk+frtDQUPn6+qpz587asWOH/bFPPvlEJpNJv/zyS6793nzzTVkslnxP40xISFCfPn1Us2ZNeXt7q27dupo4caKsVmue7bdu3ao77rjD/vM1Z86cXG0uX76s119/XREREfL29latWrU0bty4XO+1vISEhCgyMvKmn1UACo9KfRHJCbqVK1e2bzt//rzmzZunBx98UI899pguXLigjz/+WNHR0dq8ebNuu+02hz4+/fRTXbhwQSNHjpTJZNJbb72le++9VwcOHJCnp6ckaeXKlbrvvvvUuHFjxcXF6fTp0xoxYoRuvfVWh74Mw9Ddd9+ttWvX6pFHHtFtt92mFStW6MUXX9Tvv/+u6dOnO7TfsGGDvvrqKz311FOSpLi4OMXExGjcuHH64IMP7NM/3nrrLT388MNas2aNU8/LwIEDVadOHcXFxWnbtm2aN2+eQkJCNGXKFHubRx99VPPnz9eAAQP0/PPP66efflJcXJx2797t8AvLhAkTNGnSJPXu3Vu9e/fWtm3b1KtXL125csXhmBkZGercubN+//13jRw5UrVr19amTZv08ssv6/jx43r33XedGvufnThxQpJUtWpV+7bVq1dLkqpVq6bu3btrzZo1slgs6tmzp2bPnl2gqSWXL1+WxWKRl5eXw3Y/Pz9JV/9Bfuyxx667/4EDB7R06VLdf//9qlOnjv744w/NnTtXnTt31q5du1SzZk2H9n/7299kNpv1wgsv6Ny5c3rrrbc0ZMgQ/fTTT/Y2H3/8sUaOHKk77rhDY8eO1YEDB3T33XerSpUqqlWrVr7Or1OnTnr66ac1Y8YMvfLKK2rUqJEkqVGjRjp58qR69eql4OBgjR8/XoGBgTp06JC++OILp/r+7bffNGDAAD3yyCMaNmyY/v73v2v48OFq1aqVmjRpIqlw741ffvlFd955p2rUqKHY2FhZrVa98cYbCg4OzrP9xo0b9cUXX2jUqFGqWLGiZsyYofvuu09HjhzJ9VedgQMHKiwsTHFxcfrxxx81Y8YMnT171uGXEmd/TqSrU54efPBBjRw5Uo899pgaNGignTt3KiYmRpGRkXrjjTfk7e2t3377TYmJiTd9bjdt2qSWLVvm2v7rr7+qY8eO8vT01OOPP66wsDDt379fX3/9tSZPnixJ2rlzpzp27KiAgACNGzdOnp6emjt3rrp06aLvv/9et99++3WPGx8frxEjRqhNmzaKi4vTH3/8offee0+JiYn65ZdfFBgYaG+bnZ2t6OhodejQQe+88479Z2bkyJH2fp5++mkdPHhQs2bN0i+//KLExET7Z6uzny83smDBAl24cEFPPfWUMjMz9d5776lbt27avn27qlWrpgEDBuipp57SwoUL1aJFC4d9Fy5cqC5duuiWW25x+ng5z5G/v7+ee+45+fv7a82aNZowYYLOnz+vt99+26Ht2bNn1bt3bw0cOFAPPvigFi9erCeffFJeXl72X55tNpvuvvtubdy4UY8//rgaNWqk7du3a/r06dq7d6+WLl160zG1atXKqXYACslAoXzyySeGJGP16tVGamqqcfToUeOzzz4zgoODDW9vb+Po0aP2ttnZ2cbly5cd9j979qxRrVo14+GHH7ZvO3jwoCHJCAoKMs6cOWPfnpCQYEgyvv76a/u22267zahRo4aRlpZm37Zy5UpDkhEaGmrftnTpUkOSMWnSJIfjDxgwwDCZTMZvv/1m3ybJ8Pb2Ng4ePGjfNnfuXEOSUb16deP8+fP27S+//LIhyaFtXl5//XVDksN5GoZh3HPPPUZQUJD9+6SkJEOS8eijjzq0e+GFFwxJxpo1awzDMIyTJ08aXl5eRp8+fQybzWZv98orrxiSjGHDhtm3TZw40ahQoYKxd+9ehz7Hjx9vWCwW48iRIzcce1569OhhBAQEGGfPnrVve/rpp+2v25133mksWrTIePvttw1/f3+jbt26xsWLF/Ps6+23377uczh16lRDkrFhw4ZcY5dkxMTE3HCcmZmZhtVqddh28OBBw9vb23jjjTfs29auXWtIMho1auTwHn3vvfcMScb27dsNwzCMK1euGCEhIcZtt93m0O7DDz80JBmdO3e+4XgMwzBCQ0MdXp8lS5YYkoy1a9c6tPvyyy8NScbPP/980z7zOoYkY/369fZtJ0+eNLy9vY3nn3/evi0/7w1Jxuuvv27/vm/fvoafn5/x+++/27ft27fP8PDwMK79aJVkeHl5OfycJScnG5KMmTNn2rfl/JzcfffdDvuPGjXKkGQkJycbhuH8z8mfn4vly5c7tJ0+fbohyUhNTTXyIysryzCZTA7PY45OnToZFStWNA4fPuyw/c8/o/379ze8vLyM/fv327cdO3bMqFixotGpUyf7tpz3ZM77Iue917RpU+PSpUv2dsuWLTMkGRMmTLBvGzZsmCHJGD9+vMM4NmzYYEgyFi5c6LB9+fLlDtvz8/mSl5zPcF9fX+O///2vfftPP/1kSDKeffZZ+7YHH3zQqFmzpsPP6bZt2wxJxieffHLD4+T8+/Pnz46MjIxc7UaOHGn4+fkZmZmZ9m2dO3c2JBlTp061b7t8+bJx2223GSEhIcaVK1cMwzCMf/zjH4bZbM71GTRnzhxDkpGYmGjfdu3Pdo4333zTkGT88ccfNzwfAIXD9BsX6dGjh4KDg1WrVi0NGDBAFSpU0FdffeVQMf9zxdVms+nMmTPKzs5W69attW3btlx9PvDAAw6V/pwpPQcOHJAkHT9+XElJSRo2bJgqVapkb9ezZ081btzYoa///Oc/slgsevrppx22P//88zIMQ99++63D9u7duztUlnOqZ/fdd5/DtJGc7TljupknnnjC4fuOHTvq9OnTOn/+vH2ckvTcc8/lGqckffPNN5KuVsWvXLmiMWPGOEx1GDt2bK5jLlmyRB07dlTlypV16tQp+1ePHj1ktVq1fv16p8ae480339Tq1av1t7/9zaEymJ6eLkmqXr26vvnmGw0cOFAvvPCCPvroI+3fv1+ffvppvo4jSYMHD1alSpX08MMPa9WqVTp06JA+/PBDffDBB5KuXrx5I97e3vaLUq1Wq06fPm2fZpHXe27EiBEOfxW49j23ZcsWnTx5Uk888YRDu+HDhzu8B10h57ldtmzZdacx3Ujjxo3t45ek4OBgNWjQwOG9WtD3htVq1erVq9W/f3+Hv3ZERETorrvuynOfHj16OExXiYyMVEBAQJ4/Ozl/IcsxZswYSf/7+XD25yRHnTp1FB0d7bAt5/lNSEi46TS0Pztz5owMw3D4bJKk1NRUrV+/Xg8//LBq167t8FjOz6jVatXKlSvVv39/hYeH2x+vUaOGBg8erI0bN9o/C66V894bNWqUw/UNffr0UcOGDXOds3T1+pM/W7JkiSpVqqSePXs6vN6tWrWSv7+/fSpkfj5fbqR///4OlfaoqCjdfvvt9tdPkoYOHapjx445TMNcuHChfH19dd999+XreJIcrpW4cOGCTp06pY4dOyojI0N79uxxaOvh4aGRI0fav/fy8tLIkSN18uRJbd26VdLV56xRo0Zq2LChw3PWrVs3Sco1fTQvOe8Vd1iqFXBnhHoXef/997Vq1Sp99tln6t27t06dOpXnBYHz589XZGSkfHx8FBQUpODgYH3zzTc6d+5crrbX/sOY88GYM/fz8OHDkqR69erl2rdBgwYO3x8+fFg1a9bMNY87Z7pDTl/XO3ZOYLt2ekXO9mvno16PM+dkNpsVERHh0K569eoKDAy0j/N65x4cHJwrbOzbt0/Lly9XcHCww1fOBa4nT550auyStGjRIv2///f/9Mgjj+QKDDn/mA4cONBhdZf7779fHh4e2rRpk9PHyVG9enV99dVXunz5snr16qU6deroxRdf1MyZMyVJ/v7+N9zfZrNp+vTpqlevnry9vVW1alUFBwfr119/del7ztPT0yGkuULnzp113333KTY2VlWrVlW/fv30ySefODWPV8p9LtLV8/nze7Wg742TJ0/q0qVLud6nkvLc5ux4clz7/NatW1dms9k+rc/Zn5McderUyXWMBx54QO3bt9ejjz6qatWqadCgQVq8eLHTAd+45lqcnF9ObrT2eWpqqjIyMnJ9PklXP4tsNpuOHj2a574555TXvg0bNsx1zh4eHrmmIe7bt0/nzp1TSEhIrtc8PT3d/nrn5/PlRvL6bK5fv77DdUg9e/ZUjRo17Ov922w2/etf/1K/fv0KtFrMzp07dc8996hSpUoKCAhQcHCw/vKXv0hSrp/5mjVr5rp4uH79+pL+N4V037592rlzZ67nK6edM5+fOe+V611rAsA1mFPvIlFRUfbVb/r3768OHTpo8ODBSklJsQevf/7znxo+fLj69++vF198USEhIbJYLIqLi3O4oDbH9ZaKu/Yf06JwvWMXdkzO7u/KD3+bzaaePXtq3LhxeT6e84/TzaxatUpDhw5Vnz598ryYLKdiW61aNYftFotFQUFBTv/ic61OnTrpwIED2r59uy5evKjmzZvr2LFjTo39zTff1GuvvaaHH35YEydOVJUqVWQ2mzV27Ng8w1tJvueuZTKZ9Nlnn+nHH3/U119/rRUrVujhhx/W1KlT9eOPP970FxpnzsVV7w1nFOa5vd7Pg7M/J3mtdOPr66v169dr7dq1+uabb7R8+XItWrRI3bp108qVK6873ipVqshkMhX4/Vxc/vxXqhw2m+2GN8y63vUQRclisWjw4MH66KOP9MEHHygxMVHHjh2zB/H8SEtLU+fOnRUQEKA33nhDdevWlY+Pj7Zt26aXXnopX3+RyWGz2dSsWTNNmzYtz8eduY4m573y52uQALgeob4I5AT1rl27atasWRo/frwk6bPPPlN4eLi++OILh3+MX3/99QIdJzQ0VNLVSsq1UlJScrVdvXq1Lly44FD9yflzbE5fJS00NFQ2m0379u2z/xVBunpDp7S0NPs4/3zuf64Qp6am5gobdevWVXp6usPSk/n1008/6Z577lHr1q21ePHiPNcrb9WqlSTlWq3iypUrOnXqVKECg8VicbiQOuei3Jud02effaauXbvq448/dtielpZWoH9g//y85/z5Xbq6bvnBgwfVvHnzfPd5s2Datm1btW3bVpMnT9ann36qIUOG6N///rceffTRfB/rWgV9b4SEhMjHxyfPlYHy2pZf+/btc6iu//bbb7LZbPYpcc7+nNyM2WxW9+7d1b17d02bNk1vvvmmXn31Va1du/a6z4mHh4fq1q2rgwcPOmzP+Tn88+ou1woODpafn1+uzyfp6meR2Wy+bkjMOaeUlBSH917ONmfOuW7dulq9erXat29/wyU98/P5ciN5fTbv3bs310XzQ4cO1dSpU/X111/r22+/VXBwcK7pUs5Yt26dTp8+rS+++EKdOnWyb7/2tcpx7NixXEt97t27V5LsY6xbt66Sk5PVvXv3AhdbDh48aP8rIYCiw/SbItKlSxdFRUXp3XfftS9Fl1P5+nNl7qefftIPP/xQoGPUqFFDt912m+bPn+/wZ9VVq1Zp165dDm179+4tq9WqWbNmOWyfPn26TCbTdecBF7fevXtLUq5VR3KqRH369JF0Ncx6enpq5syZDs9nXquVDBw4UD/88INWrFiR67G0tDRlZ2ffcEy7d+9Wnz59FBYWpmXLll03DHTp0sVeBfzz8oPx8fGyWq3q2bPnDY/jrNTUVE2ZMkWRkZE3DaMWiyVXJXjJkiUFvttx69atFRwcrDlz5jisAhIfH6+0tLQC9ZkTKK7d/+zZs7nGnvOLjbNTcG6moO8Ni8WiHj16aOnSpfa/mkhXw/e116cUxPvvv+/wfc50q5yfU2d/Tm7kzJkzubY5+/y2a9dOW7ZscdgWHBysTp066e9//7uOHDni8FjO62ixWNSrVy8lJCQ4TEH5448/9Omnn6pDhw4KCAjI85itW7dWSEiI5syZ4zC+b7/91v4zejMDBw6U1WrVxIkTcz2WnZ1tfw/m5/PlRpYuXerws7Z582b99NNPuT5vIyMjFRkZqXnz5unzzz/XoEGDCnSjs7z+jbly5Yr9GpxrZWdn25c3zWk7d+5cBQcH24sUAwcO1O+//66PPvoo1/6XLl3SxYsXbzqurVu3ql27dvk6FwD5R6W+CL344ou6//77FR8fryeeeEIxMTH64osvdM8996hPnz46ePCg5syZo8aNG9svssyvuLg49enTRx06dNDDDz+sM2fOaObMmWrSpIlDn3379lXXrl316quv6tChQ2revLlWrlyphIQEjR07Ns/1pktC8+bNNWzYMH344Yf2PyVv3rxZ8+fPV//+/dW1a1dJVwPECy+8YF9qs3fv3vrll1/07bff5qpAv/jii/rqq68UExNjX9Lw4sWL2r59uz777DMdOnToulXrCxcuKDo6WmfPntWLL76Y62K8unXr2v+x8vb21ttvv61hw4apU6dOeuihh3TkyBG999576tixo+699177fufOnbMHtZwlBGfNmqXAwEAFBgZq9OjR9radO3dWu3btFBERoRMnTujDDz9Uenq6li1blmt6wbViYmL0xhtvaMSIEbrjjju0fft2LVy4sMDz3z09PTVp0iSNHDlS3bp10wMPPKCDBw/qk08+KXCft912mywWi6ZMmaJz587J29tb3bp106effqoPPvhA99xzj+rWrasLFy7oo48+UkBAgD3UFlZh3ht//etftXLlSrVv315PPvmk/Zfmpk2bXvdmYs46ePCg7r77bt1555364Ycf9M9//lODBw+2/yXE2Z+TG3njjTe0fv169enTR6GhoTp58qQ++OAD3XrrrerQocMN9+3Xr5/+8Y9/aO/evQ5TlGbMmKEOHTqoZcuWevzxx1WnTh0dOnRI33zzjf05mTRpkn19/FGjRsnDw0Nz587V5cuX9dZbb133mJ6enpoyZYpGjBihzp0768EHH7QvaRkWFqZnn332pufcuXNnjRw5UnFxcUpKSlKvXr3k6empffv2acmSJXrvvfc0YMCAfH2+3EhERIQ6dOigJ598UpcvX9a7776roKCgPKd7DR06VC+88IIkFWjqjSTdcccdqly5soYNG6ann35aJpNJ//jHP647xatmzZqaMmWKDh06pPr162vRokVKSkrShx9+aF/a86GHHtLixYv1xBNPaO3atWrfvr2sVqv27NmjxYsX2+9/cD0nT57Ur7/+muvibwBFoLiX2ylrcpYUy2vZPavVatStW9eoW7eukZ2dbdhsNuPNN980QkNDDW9vb6NFixbGsmXLjGHDhjksP5mzHNrbb7+dq09ds6yeYRjG559/bjRq1Mjw9vY2GjdubHzxxRe5+jQMw7hw4YLx7LPPGjVr1jQ8PT2NevXqGW+//bbDkm05x3jqqacctl1vTDnLzi1ZsuSGz1POUn3XLp+X15JsWVlZRmxsrFGnTh3D09PTqFWrlvHyyy87LMdmGFef39jYWKNGjRqGr6+v0aVLF2PHjh15Lqt24cIF4+WXXzYiIiIMLy8vo2rVqsYdd9xhvPPOO/al2/KSc97X+8pr+bZ//etfRvPmzQ1vb2+jWrVqxujRox2WAb1Zv9e+bs8++6wRHh5ueHt7G8HBwcbgwYMdlgO8kczMTOP555+3P0ft27c3fvjhB6Nz584Oy09e73XMGee1S+t98MEHRp06dQxvb2+jdevWxvr163P1eT15vT4fffSRER4eblgsFvsyhtu2bTMefPBBo3bt2oa3t7cREhJixMTEGFu2bHHqGH369Mm1Pa8xOvveyOtn77vvvjNatGhheHl5GXXr1jXmzZtnPP/884aPj49Du7x+pvJ6LnJ+Tnbt2mUMGDDAqFixolG5cmVj9OjRDss4GobzPyfXey6+++47o1+/fkbNmjUNLy8vo2bNmsaDDz6Ya3nPvFy+fNmoWrWqMXHixFyP7dixw7jnnnuMwMBAw8fHx2jQoIHx2muvObTZtm2bER0dbfj7+xt+fn5G165djU2bNjm0uXZJyxyLFi0yWrRoYXh7extVqlQxhgwZ4rBspGFcXdKyQoUK1x3/hx9+aLRq1crw9fU1KlasaDRr1swYN26ccezYMXub/Hy+XOvPn5dTp041atWqZXh7exsdO3a0L0t6rePHjxsWi8WoX7/+Dfv+s7w+PxMTE422bdsavr6+Rs2aNY1x48YZK1asyPVcdu7c2WjSpImxZcsWo127doaPj48RGhpqzJo1K9dxrly5YkyZMsVo0qSJ4e3tbVSuXNlo1aqVERsba5w7d87eLq/nZvbs2Yafn1+uz0AArmcyjBK4Ag4Ayqj+/ftr586dec6nLksmTpyoTz75RPv27bvuRbVw3qlTp1SjRg1NmDBBr732WkkPx2VatGihLl265LrBIQDXY049ABTQtfcJ2Ldvn/7zn/+oS5cuJTOgYvTss88qPT1d//73v0t6KGVCzrU3Dz30UEkPxWWWL1+uffv26eWXXy7poQDlApV6ACigGjVqaPjw4QoPD9fhw4c1e/ZsXb58Wb/88kuea5QD11qzZo127dql1157TV27dtUXX3xR0kMC4KYI9QBQQCNGjNDatWt14sQJeXt7q127dnrzzTfVsmXLkh4a3ESXLl20adMmtW/fXv/85z8d7kALAPlBqAcAAADcHHPqAQAAADdHqAcAAADcHKEeAAAAcHOEegAAAMDNEeoBAAAAN0eoBwAAANwcoR4AAABwc4R6AAAAwM0R6gEAAAA351HSAwAAAEDpY7ValZWVVdLDKNc8PT1lsVicakuoBwAAgJ1hGDpx4oTS0tJKeiiQFBgYqOrVq8tkMt2wHaEeAAAAdjmBPiQkRH5+fjcNkygahmEoIyNDJ0+elCTVqFHjhu0J9QAAAJB0dcpNTqAPCgoq6eGUe76+vpKkkydPKiQk5IZTcbhQFgAAAJJkn0Pv5+dXwiNBjpzX4mbXNxDqAQAA4IApN6WHs68FoR4AAAAulW213fB7uB6hHgAAAC5htRmy2mxavvOERi3cqiHzftSohVu1fOcJWW02WW1GSQ8xT/Hx8QoMDCx0PyaTSUuXLi10PwVRLi6UvXDlgnaf3q1dp3fp2MVjumy9LMMw5G3xVohfiBoFNVLjoMaq4lOlpIcKAADglmyGofV7UzXus1+Vmn7Z4bH/bD+hYH9vvTUgUp0bBMvs4uk9w4cPV1paWokF6vx4//339fbbb+vEiRNq3ry5Zs6cqaioqEL3W2ZD/fH041qyd4m+OfiNjqUfkySZTWaZZZahq78lmmSSIUNWwypJqupbVb1Ce+mBBg8oPDC8xMYOAADgTqy2q4H+0QVbrluNT02/rEcXbNG8oa3VqX6wLObyN29/0aJFeu655zRnzhzdfvvtevfddxUdHa2UlBSFhIQUqu8yN/3m5xM/a8x3YxT9ebQ+3vGxPdBLks2wKdvIltWwympY7f+f49SlU1qUskj9Evpp+PLh+u7IdzKM0vlnIgAAgNLD0LjPfr3p9BqrzdC4z38tpjH9z7Rp09SsWTNVqFBBtWrV0qhRo5Senp6r3dKlS1WvXj35+PgoOjpaR48edXg8ISFBLVu2lI+Pj8LDwxUbG6vs7Ox8jeOxxx7TiBEj1LhxY82ZM0d+fn76+9//XuhzLDOh/vyV83ot8TU9vOJhbfh9gwwZshn5vygjJ+T/cvIXjV07Vk9995ROZpx09XABAADKhGyrTd/uOJFrys31pF64rOU7jhfrxbNms1kzZszQzp07NX/+fK1Zs0bjxo1zaJORkaHJkydrwYIFSkxMVFpamgYNGmR/fMOGDRo6dKieeeYZ7dq1S3PnzlV8fLwmT57s1BiuXLmirVu3qkePHg7j6tGjh3744YfCn2OheygFNv6+UXd/ebe+2v+VJDlU3wsq5xeCTcc22fumag8AAODIw2LWf7Yfz9c+/9l+Qh6W4ouhY8eOVdeuXRUWFqZu3bpp0qRJWrx4sUObrKwszZo1S+3atVOrVq00f/58bdq0SZs3b5YkxcbGavz48Ro2bJjCw8PVs2dPTZw4UXPnznVqDKdOnZLValW1atUctlerVk0nTpwo9Dm6/Zz6f+76p6b8PEVmmWWT63/jsxpWZWRn6NWNr2rPmT16sfWLrN0KAADwJ+cu3fjGSIVtX1irV69WXFyc9uzZo/Pnzys7O1uZmZnKyMiw39zJw8NDbdq0se/TsGFDBQYGavfu3YqKilJycrISExMdKvNWqzVXPyXFrUP9vO3z9N629ySpSAJ9jpwLa/+x6x/KzM7Ua21fI9gDAAD8n0q+nkXavjAOHTqkmJgYPfnkk5o8ebKqVKmijRs36pFHHtGVK1ecDuPp6emKjY3Vvffem+sxHx+fm+5ftWpVWSwW/fHHHw7b//jjD1WvXt25k7kBt51+szhlsT3QF6cle5do+rbpxX5cAACA0ijbalPvZjXytU/vZtWLbU791q1bZbPZNHXqVLVt21b169fXsWPHcrXLzs7Wli1b7N+npKQoLS1NjRo1kiS1bNlSKSkpioiIyPVlNt88Unt5ealVq1b67rvv7NtsNpu+++47tWvXrtDn6ZaV+pQzKZr8k3MXJRSFT3Z8otbVWqvTrZ1KbAwAAAClgYfFrLuaVlewv7dTF8sGV/TWnU1ruHxJy3PnzikpKclhW1BQkCIiIpSVlaWZM2eqb9++SkxM1Jw5c3Lt7+npqTFjxmjGjBny8PDQ6NGj1bZtW/sa8hMmTFBMTIxq166tAQMGyGw2Kzk5WTt27NCkSZOcGuNzzz2nYcOGqXXr1oqKitK7776rixcvasSIEYU+f7er1GfZsvTyhpdlUslNfzHJpNcSX9O5y+dKbAwAAAClh0lvDYi8aVC3mE16677IIhnBunXr1KJFC4ev2NhYNW/eXNOmTdOUKVPUtGlTLVy4UHFxcbn29/Pz00svvaTBgwerffv28vf316JFi+yPR0dHa9myZVq5cqXatGmjtm3bavr06QoNDXV6jA888IDeeecdTZgwQbfddpuSkpK0fPnyXBfPFoTJcLMlXWYnzdbs5Nn2ee4lxWwyKyY8RpM7lNxfDAAAAFwpMzNTBw8eVJ06dZyaJ/5nNsPQ9ympGvf5r0q9kLtiH1zRW2/dVzR3lC3LnH1N3CrUn7p0Sj2X9FS24fwi/0VtUcwiNQ5qXNLDAAAAKLTChHpJ9ptPLd9xXP/ZfkLnLmWpkq+nejerrjubXp13Xx7vJFsYzr4mbjWn/st9XxbohlJFxWKyaNGeRYptH1vSQwEAAChxOYE9ukl19Ymsad+ebbUR5ouY24T6bFu2gn2D9Xm/z1WzQk2du3xOv576VTN/manD5w87tDXJpPsb3K/769+vsIAwZWZnKuVsit76+S3tPbvX3u6xZo+pWXAzRVaNVJBvkD5I+kCzk2fnefy2NdrqsWaPqV7lerKYLTp8/rA+3f2pvj7wtZ5r/ZwqeVcq0vMHAABwF9feWKo4bzRVXrlNqD+TeUbtb2mvlYdXau/ZvarqW1UPNnxQi2MWa8h/hui3tN/sbSe2n6je4b319f6v9a89/5Kvh68aVWmkIJ8ghz6fbvm0UjNStfvMbnW4pcN1j92lVhe91/U9JacmX53PbxiKDotWXMc4VfaprK/3f62/NP5LkZ07AAAAcCNuE+qXH1yumb/MVKY102HbF/2+0CNNH9HLG1+WJEWHRqtfRD89s/YZrTmy5oZ9Rn8WrWMXjynQO1AbBm24brsHGz6o1EupemTFI8qyXb0D2pK9S/RV/6/Ur24/zdg2g1APAACAEuM2fwtZfmi5Q6CXpCMXjmh/2n6FB4bbtz3U5CH9mvqr1hxZI5NM8vXwvW6fxy7mvvFAXip4VtD5y+ftgV6SrIZVZy+fVaY1U9tPbc/n2QAAAACu4xah3mqzKuVMSp6PBfkE6WzmWUlXw3ezqs208/ROPd3iaf0w+AdtHrJZ3977raJDowt8/C0ntqhe5Xoafdto1apYS7dWvFUjI0eqSVATfbLjE529fFapGakF7h8AAAAoDLeYfnP4/GFdsV3JtT0mPEbVKlTTrKRZkqRaFWvJbDLrzrA7ZTWsmrZ1mtKvpGtIoyF6q/NbSl+drsRjifk+/txf5+oW/1v0WORjGtl8pCQpIytDz617TmuPrpUk7T6zW8F+wYU4SwAAAKBg3CLUp11Oy7WtTkAdvXL7K0o6maSv9n8lSfLz8JMkVfaprMHfDLZPi1l7dK2W37dcj0c+XqBQf8V6RYfPH9aqw6u0+vBqWUwWDag/QHEd4/T4ysf166lfubssAABADmuWZPG8/vdwObeYfnNtlT7IJ0jv93hf6VfS9dy65+xr1+fMuf/vhf86zHO/lH1J3x/9Xs2qNpPFZMn38V+5/RV1rtVZL37/opYfWq5vDn6jx1Y+ptSMVL0U9ZIk6bI1953TAAAAyhWbVbJlS7u/lhYPkxb0u/rf3V9f3W6zlvQI8xQfH6/AwMBC92MymbR06dJC91MQbhHq/xzE/T39NbvHbFX0rKgnVj+h1Ev/m8ueM6/99KXTufo4k3lGnhbPG144mxcPs4fuqXeP1v93vQz97+a72Ua2Nv6+UU2CmsjD7CEPs1v80QMAAKBoGDbpt++kaY2kz0ZIu5ZKB9Zd/e9nI65u/+27q+1cbPjw4erfv7/L+3W19evXq2/fvqpZs6bLfwFwi1CfE8S9zF6a1X2WQgNCNXrNaB04d8ChXeqlVKVmpCrELyRXH8F+wcrMztTFrIv5Onagd6A8zZ55Vvg9zB6ymC2ymCzy8cj/rZQBAADKBJtV2rda+vcgKf1k3m3ST159fN/qUluxL2oXL15U8+bN9f7777u8b7cI9aEBoTKbzHqn8zuKDI7UC9+/oOTU5DzbLj+0XDX8a6hdjXb2bYHegepaq6s2n9jsUG13xpnMMzp/+by61e7mUI339fBVl1pddCDtgC5bL6tOQJ2CnRwAAIDbM6Svnrp5WLdZpa9GX21fjKZNm6ZmzZqpQoUKqlWrlkaNGqX09PRc7ZYuXap69erJx8dH0dHROnr0qMPjCQkJatmypXx8fBQeHq7Y2FhlZ2c7PY677rpLkyZN0j333FPoc7qWW8wZqehVUa+3e11da3fV2qNrVcm7kmLCYxzaLDuwTJL08faPFR0WrWldpmnBrgVKz0rX/fXvl4fZQ+9te89hn5jwGNX0rykfy9Uqe6tqrfR45OOSpK/3f63jF4/LZtgUvzNeT7d8Wgt7L9TX+7+W2WTWvfXuVfUK1TV+/Xh5mD0c1soHAAAoN6xZV+fMX69Cf630P662bxhTbBfPms1mzZgxQ3Xq1NGBAwc0atQojRs3Th988IG9TUZGhiZPnqwFCxbIy8tLo0aN0qBBg5SYeHWRlQ0bNmjo0KGaMWOGOnbsqP379+vxx6/mxtdff71YzuNG3CLUS1Lz4OaSpK61uqprra65Hs8J9aczT2vYt8P0fOvn9VDjh+Rh9lByarJe3vCy9p7d67DPvfXuVZvqbezf317jdt1e43ZJ0rY/tun4xeOSpI+2f6Tf03/XkEZD9GTzJ+Vp8dTes3v17NpntfrIajWq0kieZq7oBgAA5ZDFU9qVkL99diVITVxfrb6esWPH2v8/LCxMkyZN0hNPPOEQ6rOysjRr1izdfvvVLDh//nw1atRImzdvVlRUlGJjYzV+/HgNGzZMkhQeHq6JEydq3LhxhPr8SPw9Ufcm3Cubbn5xxX/T/6tn1z1703YPr3jY6eP/5+B/9J+D/8m13WKyqEVIC6f7AQAAKHMy0/LX/lI+2xfS6tWrFRcXpz179uj8+fPKzs5WZmamMjIy5Od3dUl0Dw8PtWnzv2Jvw4YNFRgYqN27dysqKkrJyclKTEzU5MmT7W2sVmuufkqKW8ypl6Te4b1lMplKehi5WA2r7o64u6SHAQAAUHJ8AvPX3jef7Qvh0KFDiomJUWRkpD7//HNt3brVfqHqlSu5b256Penp6YqNjVVSUpL9a/v27dq3b598fEp+wRS3qdRX9a2qnqE9terwKlmN0nHFtFlmNQxqqCZBTUp6KAAAACXDmiU17nd16UpnNe5XbDek2rp1q2w2m6ZOnSqz+Wo9e/HixbnaZWdna8uWLYqKipIkpaSkKC0tTY0aNZIktWzZUikpKYqIiCjyMReE24R6SRrUcJCWH1pe0sOws8mmIY2GlPQwAAAASo7FU2p8t+Qf4tzFsv7VpEZ9JRff4+fcuXNKSkpy2BYUFKSIiAhlZWVp5syZ6tu3rxITEzVnzpxc+3t6emrMmDGaMWOGPDw8NHr0aLVt29Ye8idMmKCYmBjVrl1bAwYMkNlsVnJysnbs2KFJkyY5Ncb09HT99ttv9u8PHjyopKQkValSRbVr1y74ycuNpt9IUsuQlmoe3LxAd4V1NbPMqlGhhqLDokt6KAAAACXMJN39vmS+SUYzW6R+719t72Lr1q1TixYtHL5iY2PVvHlzTZs2TVOmTFHTpk21cOFCxcXF5drfz89PL730kgYPHqz27dvL399fixYtsj8eHR2tZcuWaeXKlWrTpo3atm2r6dOnKzQ01OkxbtmyxT42SXruuefUokULTZgwodDnbzIMo3gXCi2kQ+cO6d6v7lWWLaukh6IxIWP0SK9HZLGU/C8ZAAAAhZWZmamDBw+qTp06+Z8nbtiu3ljqq9FXl628ln816e5ZUr0eksmt6solytnXxO1CvSQt2LlAb295u8SOb5ZZHfw7qPqu6goODla/fv1Uo0aNEhsPAACAKxQq1Ev/d/Mp4+o69LsSrq5y4xt4dQ59o76STDev5sNBmQ71VptVD694WMmpycV+0azFZFFN/5r6rO9nOnfqnBISEpSamqoOHTqoU6dOVO0BAIDbKnSoz3HtRbDFdFFsWeTsa+KWf/uwmC2a2X2mwiuFF+v8eovJoio+VfRxr4/l5+mnGjVq6LHHHlOHDh20ceNGffTRRzp+/HixjQcAAKBUujbAE+iLnFuGekkK8ArQx9Efq25gXZmLYV6WxWRRVd+qmn/nfNXw/99UG4vFoq5du+rRRx+VJM2bN09r166V1Vo6lt0EAABA2ee2oV6SKvtUVvyd8epQs4MkyVQEV1LnaFiloRb2XqhaAbXyfJyqPQAAAEqKW4d6SaroVVGzus/S5A6T5evh69LpOBaTRR5mDz3f6nkt7L1Q1SpUu3F7qvYAAAAoAW55oez1nMw4qb/99DetPrJaJpNJNsNWoH4sJoushlVR1aP0attXFV4pPN99WK1WrV+/Xhs3bmSFHAAA4BZcdqEsXKZMr35zM8fSj+mzvZ9pUcoinb9y3j7n/noh3ySTzCazrIZVPhYf3VPvHj3Q4AHVDaxb6LEcP36cFXIAAIBbINSXPuU61Oe4Yr2iLSe2aNeZXdp5aqd+PfWrUjNSZeh/p1zZu7KaVm2qplWbqnFQY7Wp3kYVPCu4dBxU7QEAgDtwVajPtmXLw+xx3e/hPEL9dRiGoSxblgwZ8jJ7yWQquotrr0XVHgAAlGaFDfVW29XrCFcfXq2Vh1fq/JXzCvAKUK/QXuoR2kPS1aXJS5v4+HiNHTtWaWlpherHZDLpyy+/VP/+/V0yLsn516Tc/cpkMpnkZfEqkWPnrJCTU7VPSUmhag8AAMoEm2HTpmOb9FriazqdedrhsZWHVyrIJ0gT209U+1vau3w58uHDhystLU1Lly51ab+uFhcXpy+++EJ79uyRr6+v7rjjDk2ZMkUNGjQodN9uv/qNu2GFHAAAUNZYbVYl/p6oMWvG5Ar0OU5nntaYNWOU+HuivaJf3nz//fd66qmn9OOPP2rVqlXKyspSr169dPHixUL3TagvIaxrDwAAypLXEl+T1bhxWLcaVk3YNKGYRvQ/06ZNU7NmzVShQgXVqlVLo0aNUnp6eq52S5cuVb169eTj46Po6GgdPXrU4fGEhAS1bNlSPj4+Cg8PV2xsrLKzs50ex/LlyzV8+HA1adJEzZs3V3x8vI4cOaKtW7cW+hwJ9SWIqj0AAHB32bZsrTq86roV+mudunRKq4+sVrbN+TBcWGazWTNmzNDOnTs1f/58rVmzRuPGjXNok5GRocmTJ2vBggVKTExUWlqaBg0aZH98w4YNGjp0qJ555hnt2rVLc+fOVXx8vCZPnlzgcZ07d06SVKVKlQL3kYNQXwpQtQcAAO7Kw+yhVYdX5WufVYdWFetqOGPHjlXXrl0VFhambt26adKkSVq8eLFDm6ysLM2aNUvt2rVTq1atNH/+fG3atEmbN2+WJMXGxmr8+PEaNmyYwsPD1bNnT02cOFFz584t0JhsNpvGjh2r9u3bq2nTpoU+x3J3oWxplVO1b9iwoRISEjRv3jxWyAEAAG7h/JXzRdq+sFavXq24uDjt2bNH58+fV3Z2tjIzM5WRkSE/Pz9JkoeHh9q0aWPfp2HDhgoMDNTu3bsVFRWl5ORkJSYmOlTmrVZrrn6c9dRTT2nHjh3auHGjS86RSn0pQ9UeAAC4mwCvgCJtXxiHDh1STEyMIiMj9fnnn2vr1q16//33JUlXrlxxup/09HTFxsYqKSnJ/rV9+3bt27cv38t/jh49WsuWLdPatWt166235mvf6yHUl0LMtQcAAO4i25atXqG98rVPz7CexTanfuvWrbLZbJo6daratm2r+vXr69ixY7naZWdna8uWLfbvU1JSlJaWpkaNGkmSWrZsqZSUFEVEROT6Mpudi9SGYWj06NH68ssvtWbNGtWpU8c1Jymm35RqrGsPAABKOw+zh3qE9lCQT5BTF8tW9a2qHrV7uPwmVOfOnVNSUpLDtqCgIEVERCgrK0szZ85U3759lZiYqDlz5uTa39PTU2PGjNGMGTPk4eGh0aNHq23btoqKipIkTZgwQTExMapdu7YGDBggs9ms5ORk7dixQ5MmTXJqjE899ZQ+/fRTJSQkqGLFijpx4oQkqVKlSvL19S3U+VOpL+Wo2gMAAHcwsf1EWUw3DuoWk0Vv3PFGkRx/3bp1atGihcNXbGysmjdvrmnTpmnKlClq2rSpFi5cqLi4uFz7+/n56aWXXtLgwYPVvn17+fv7a9GiRfbHo6OjtWzZMq1cuVJt2rRR27ZtNX36dIWGhjo9xtmzZ+vcuXPq0qWLatSoYf/683EKymQYhlHoXlAsrFarvWofHBxM1R4AALhUZmamDh48qDp16uR7nrjNsCnx90RN2DRBpy6dyvV4Vd+qeuOON4rkjrJlmbOvCaHeDR0/flwJCQlKTU1lhRwAAOAyhQn1kux3il19ZLVWHVql81fOK8ArQD3DeqpH7R6S5PJpN2Udob6Mo2oPAABcrbChPke2LdthHfprv4fznH1N+NuHm2KuPQAAKK2uDfAE+qJHqHdzrGsPAAAAQn0ZQNUeAACgfCPUlyFU7QEAAMonQn0ZQ9UeAACg/CHUl1FU7QEAQEkxsrNv+D1cj0uRy7Ccqn3Dhg2VkJCgefPmsa49AAAoMsb/zQw4v2qVLixfIev587IEBKjindEK6NVLkmQigxQJKvXlAFV7AABQ1AybTRc3Jmpf5y469uxzurBihTJ++EEXVqzQsWef077OXXRxY6IMm62kh5pLfHy8AgMDC92PyWTS0qVLC91PQRDqywnm2gMAgKJiWK26uGGjjo4aJeupU3m2sZ46paOjRuniho32ir6rDB8+XP3793dpn0Vh9uzZioyMVEBAgAICAtSuXTt9++23LumbUF/OULUHAABF4dirr0o3C+tWq47/v/9XPAMqhW699Vb97W9/09atW7VlyxZ169ZN/fr1086dOwvdN6G+HKJqDwAAXMXIztb5FSuvW6G/VnZqqi6sWlWsF89OmzZNzZo1U4UKFVSrVi2NGjVK6enpudotXbpU9erVk4+Pj6Kjo3X06FGHxxMSEtSyZUv5+PgoPDxcsbGxys7HefTt21e9e/dWvXr1VL9+fU2ePFn+/v768ccfC32OhPpyjKo9AAAoLJOHhy6sWJGvfc4vXyGTR/Gt12I2mzVjxgzt3LlT8+fP15o1azRu3DiHNhkZGZo8ebIWLFigxMREpaWladCgQfbHN2zYoKFDh+qZZ57Rrl27NHfuXMXHx2vy5MkFGpPVatW///1vXbx4Ue3atSvU+UmE+nKPqj0AACgs6/nz+Wpvy2f7who7dqy6du2qsLAwdevWTZMmTdLixYsd2mRlZWnWrFlq166dWrVqpfnz52vTpk3avHmzJCk2Nlbjx4/XsGHDFB4erp49e2rixImaO3duvsayfft2+fv7y9vbW0888YS+/PJLNW7cuNDnyJKWkPS/qv369eu1ceNGpaSkqF+/fqpRo0ZJDw0AAJRyloCAfLU357N9Ya1evVpxcXHas2ePzp8/r+zsbGVmZiojI0N+fn6SJA8PD7Vp08a+T8OGDRUYGKjdu3crKipKycnJSkxMdKjMW63WXP3cTIMGDZSUlKRz587ps88+07Bhw/T9998XOthTqYcdVXsAAJBfRna2Kt4Zna99Au6MLrY59YcOHVJMTIwiIyP1+eefa+vWrXr//fclSVeuXHG6n/T0dMXGxiopKcn+tX37du3bt08+Pj5O9+Pl5aWIiAi1atVKcXFxat68ud577718n9e1qNQjF6r2AADAWSYPDwX06qU/qlZ16mJZj+BgVezZs9huQrV161bZbDZNnTpVZvPVeva1U28kKTs7W1u2bFFUVJQkKSUlRWlpaWrUqJEkqWXLlkpJSVFERIRLx2ez2XT58uVC90OoR564Gy0AAMiPmpMn6+ioUTde1tJiUY3Jk4rk+OfOnVNSUpLDtqCgIEVERCgrK0szZ85U3759lZiYqDlz5uTa39PTU2PGjNGMGTPk4eGh0aNHq23btvaQP2HCBMXExKh27doaMGCAzGazkpOTtWPHDk2a5Nw5vfzyy7rrrrtUu3ZtXbhwQZ9++qnWrVunFfm80DgvTL/BDbFCDgAAuBmTxaIKHTuo1gcfyCM4OM82HsHBqvXBB6rQoUORVOnXrVunFi1aOHzFxsaqefPmmjZtmqZMmaKmTZtq4cKFiouLy7W/n5+fXnrpJQ0ePFjt27eXv7+/Fi1aZH88Ojpay5Yt08qVK9WmTRu1bdtW06dPV2hoqNNjPHnypIYOHaoGDRqoe/fu+vnnn7VixQr17Nmz0OdvMgzDKHQvKBeOHz+uhIQEpaamUrUHAKAMyszM1MGDB1WnTp18zRPPkXOn2AurVun88hWynT8vc0CAAu6MVsX/C67FNe2mrHD2NSHUI1+sVqt9rn1wcDBz7QEAKEMKG+pzGNnZDuvQX/s9nOfsa8L0G+QLK+QAAICbuTbAE+iLHqEeBcJcewAAgNKDUI8Co2oPAABQOhDqUWhU7QEAAEoWoR4uQdUeAACg5BDq4VJU7QEAAIofoR4uR9UeAIDyzWa13fB7uB7rC6HI5FTtc9a1T0lJYV17AADKMJvNkAxp/y+p2r/tpC5nZMvbz0N1W4aobosQySSZzaaSHmaZRKUeRYqqPQAA5YNhGDq664zmv5yolfN2av+2VP13z1nt35aqlfN2av7LiTq664xK431P4+PjFRgYWOh+TCaTli5dWuh+CoJQj2LBXHsAAMoum83QkZ1n9M0Hvyrj/JU822Scv6JvPvhVR3aeuVrRd6Hhw4erf//+Lu2zqP3tb3+TyWTS2LFjXdIfoR7Fhqo9AABllCGtWbBbxk3CumEztGbBbqn0FeuL1c8//6y5c+cqMjLSZX0S6lHsqNoDAFB22Kw27f/l5HUr9NfKOH9FB5JOFuvFs9OmTVOzZs1UoUIF1apVS6NGjVJ6enqudkuXLlW9evXk4+Oj6OhoHT161OHxhIQEtWzZUj4+PgoPD1dsbKyys7PzNZb09HQNGTJEH330kSpXrlyo8/ozQj1KBFV7AADKBrPFrP3bTuZrn/3bUmW2FF8MNZvNmjFjhnbu3Kn58+drzZo1GjdunEObjIwMTZ48WQsWLFBiYqLS0tI0aNAg++MbNmzQ0KFD9cwzz2jXrl2aO3eu4uPjNXny5HyN5amnnlKfPn3Uo0cPl5xbDkI9ShRVewAA3N/ljPxVqzMzsopoJHkbO3asunbtqrCwMHXr1k2TJk3S4sWLHdpkZWVp1qxZateunVq1aqX58+dr06ZN2rx5syQpNjZW48eP17BhwxQeHq6ePXtq4sSJmjt3rtPj+Pe//61t27YpLi7OpecnEepRClC1BwDAvXn75W+VdB8/zyIaSd5Wr16t7t2765ZbblHFihX10EMP6fTp08rIyLC38fDwUJs2bezfN2zYUIGBgdq9e7ckKTk5WW+88Yb8/f3tX4899piOHz/u0M/1HD16VM8884wWLlwoHx8fl58joR6lBlV7AADcj81qU92WIfnap27L4GKbU3/o0CHFxMQoMjJSn3/+ubZu3ar3339fknTlinPXAUhX58LHxsYqKSnJ/rV9+3bt27fPqZC+detWnTx5Ui1btpSHh4c8PDz0/fffa8aMGfLw8Ch0MZObT6FUyanaN2zYUAkJCZo3b546dOigTp06yWKxlPTwAADANcwWs+q2CJFfwD6nLpb1C/BS+G0hMluK5yZUW7dulc1m09SpU2U2X61nXzv1RpKys7O1ZcsWRUVFSZJSUlKUlpamRo0aSZJatmyplJQURUREFGgc3bt31/bt2x22jRgxQg0bNtRLL71U6JxDqEepxN1oAQBwIyap29BG+uaDX2+4rKXJbFK3oY2kIsjz586dU1JSksO2oKAgRUREKCsrSzNnzlTfvn2VmJioOXPm5Nrf09NTY8aMsVfOR48erbZt29pD/oQJExQTE6PatWtrwIABMpvNSk5O1o4dOzRp0qSbjq9ixYpq2rSpw7YKFSooKCgo1/aCYPoNSi3m2gMA4B7MZpNqN6miPqMi5RfglWcbvwAv9RkVqdpNqshsdn2qX7dunVq0aOHwFRsbq+bNm2vatGmaMmWKmjZtqoULF+Z5oaqfn59eeuklDR48WO3bt5e/v78WLVpkfzw6OlrLli3TypUr1aZNG7Vt21bTp09XaGioy8+lIExGabxXL3ANq9Vqr9oHBwdTtQcAoAhkZmbq4MGDqlOnToEu5rTZDMmQDiSd1P5tqcrMyJKPn6fqtgxW+G0hkklFEujLMmdfE0I93Mrx48eVkJCg1NRU5toDAOBihQ31OWxWm8M69Nd+D+c5+5rw7MKtsEIOAACl37UBnkBf9HiG4XaYaw8AAOCIUA+3RdUeAADgKkI93BpVewAAAEI9ygiq9gAAoDwj1KPMoGoPAADKK0I9yhyq9gAAlCyrNfuG38P1PEp6AEBRyKnaN2zYUAkJCZo3bx7r2gMAUMRs//fX8d82/6C9P25U5sV0+VTwV/22HVQv6g5Jkpl/h4sEN59CmcfdaAEAcE5hbj5l2Gw6mLxNK2a/q4xzabke96sUqOgnx6pO85YymUvXZJH4+HiNHTtWaWlpherHZDLpyy+/VP/+/V0yLombTwF2zLUHAKBo2axWHUzepqVvvZFnoJekjHNpWvrWGzqYvM1e0XeV4cOHuzRIF5W//vWvMplMDl8NGzZ0Sd+EepQbzLUHAKDorJj9rgyb7YZtDJtNK+e8V0wjKp2aNGmi48eP2782btzokn4J9ShXqNoDAOBaVmu29v6UeN0K/bUupp3Vvs0/FOvFs9OmTVOzZs1UoUIF1apVS6NGjVJ6enqudkuXLlW9evXk4+Oj6OhoHT161OHxhIQEtWzZUj4+PgoPD1dsbKyys/N3Hh4eHqpevbr9q2rVqoU6txyEepRLVO0BAHANi8VD+35KzNc+e3/cKIul+NZrMZvNmjFjhnbu3Kn58+drzZo1GjdunEObjIwMTZ48WQsWLFBiYqLS0tI0aNAg++MbNmzQ0KFD9cwzz2jXrl2aO3eu4uPjNXny5HyNZd++fapZs6bCw8M1ZMgQHTlyxDXn6JJeADdE1R4AANfIvJi76n0jl/PZvrDGjh2rrl27KiwsTN26ddOkSZO0ePFihzZZWVmaNWuW2rVrp1atWmn+/PnatGmTNm/eLEmKjY3V+PHjNWzYMIWHh6tnz56aOHGi5s6d6/Q4br/9dsXHx2v58uWaPXu2Dh48qI4dO+rChQuFPkeWtES5l1O1z1khJyUlhRVyAADIB58K/vlq753P9oW1evVqxcXFac+ePTp//ryys7OVmZmpjIwM+fn5Sbo6LaZNmzb2fRo2bKjAwEDt3r1bUVFRSk5OVmJiokNl3mq15urnRu666y77/0dGRur2229XaGioFi9erEceeaRQ50ilHhBVewAACspqzVb9th3ytU/9th2KbU79oUOHFBMTo8jISH3++efaunWr3n//fUnSlStXnO4nPT1dsbGxSkpKsn9t375d+/bty/fynzkCAwNVv359/fbbbwXa/8+o1AN/QtUeAID8sVg8VC/qDvlVCnTqYtkKgZVVL6pdsd2EauvWrbLZbJo6darM/7c+/rVTbyQpOztbW7ZsUVRUlCQpJSVFaWlpatSokSSpZcuWSklJUUREhMvGlp6erv379+uhhx4qdF+EeuAa3I0WAID8i35yrJa+9cYNl7U0mc2KfuKZIjn+uXPnlJSU5LAtKChIERERysrK0syZM9W3b18lJiZqzpw5ufb39PTUmDFjNGPGDHl4eGj06NFq27atPeRPmDBBMTExql27tgYMGCCz2azk5GTt2LFDkyZNcmqML7zwgvr27avQ0FAdO3ZMr7/+uiwWix588MFCnz/Tb4DrYIUcAACcY7ZYVKd5S/UfN0EVAivn2aZCYGX1HzdBYc1bFkmVft26dWrRooXDV2xsrJo3b65p06ZpypQpatq0qRYuXKi4uLhc+/v5+emll17S4MGD1b59e/n7+2vRokX2x6Ojo7Vs2TKtXLlSbdq0Udu2bTV9+nSFhoY6Pcb//ve/evDBB9WgQQMNHDhQQUFB+vHHHxUcHFzo8zcZhmEUuhegjDt+/LgSEhKUmppK1R4AUGZlZmbq4MGDqlOnToHmiefcKXbf5h+098eNunwxXd4V/FW/bQfVi2onScU27aascPY1IdQDTrJarfa59sHBwcy1BwCUOYUN9Tms1myHdeiv/R7Oc/Y1YfoN4CRWyAEAwDnXBngCfdEj1AP5xFx7AABQ2hDqgQKgag8AAEoTQj1QCFTtAQBAaUCoBwqJqj0AAChphHrARajaAwCAkkKoB1yIqj0AAJJhtd3we7geoR4oAlTtAQDlkWEzZNgMXdp5WqcX7lbqvO06vXC3Lu08bX+sNIqPj1dgYGCh+zGZTFq6dGmh+ykIQj1QRKjaAwDKE8MwlLn3rI6/+ZPOfLpHl7af0uXf0nRp+ymd+XSPjr/5kzL3nlVR3Pd0+PDh6t+/v8v7LQq///67/vKXvygoKEi+vr5q1qyZtmzZUuh+CfVAEaNqDwAo6wybocyUszq9YKds6Vl5trGlZ+n0gp3KTDlbaiv2Re3s2bNq3769PD099e2332rXrl2aOnWqKleuXOi+CfVAMaBqDwAo685+tle62dR5m3T2873FMp4/mzZtmpo1a6YKFSqoVq1aGjVqlNLT03O1W7p0qerVqycfHx9FR0fr6NGjDo8nJCSoZcuW8vHxUXh4uGJjY5Wdne30OKZMmaJatWrpk08+UVRUlOrUqaNevXqpbt26hT5HQj1QjKjaAwDKGsNq06Udp65bob+W7UKWLu04VawXz5rNZs2YMUM7d+7U/PnztWbNGo0bN86hTUZGhiZPnqwFCxYoMTFRaWlpGjRokP3xDRs2aOjQoXrmmWe0a9cuzZ07V/Hx8Zo8ebLT4/jqq6/UunVr3X///QoJCVGLFi300UcfueYcXdILAKdRtQcAlCUmi1mXtp/K1z6Xtp+SyVJ8MXTs2LHq2rWrwsLC1K1bN02aNEmLFy92aJOVlaVZs2apXbt2atWqlebPn69NmzZp8+bNkqTY2FiNHz9ew4YNU3h4uHr27KmJEydq7ty5To/jwIEDmj17turVq6cVK1boySef1NNPP6358+cX+hw9Ct0DgALJqdqvX79eGzduVEpKivr166caNWqU9NAAAMgX2yXnp6AUpH1hrV69WnFxcdqzZ4/Onz+v7OxsZWZmKiMjQ35+fpIkDw8PtWnTxr5Pw4YNFRgYqN27dysqKkrJyclKTEx0qMxbrdZc/dyIzWZT69at9eabb0qSWrRooR07dmjOnDkaNmxYoc6RSj1QgqjaAwDKArNv/urE+W1fGIcOHVJMTIwiIyP1+eefa+vWrXr//fclSVeuXHG6n/T0dMXGxiopKcn+tX37du3bt08+Pj5O9VGjRg01btzYYVujRo105MgR50/oOqjUA6UAVXsAgLsyrDb5Nquaryk4vs2qyrDaimUKztatW2Wz2TR16lSZzVePd+3UG0nKzs7Wli1bFBUVJUlKSUlRWlqaGjVqJElq2bKlUlJSFBERUeCxtG/fXikpKQ7b9u7dq9DQ0AL3mYNQD5QSOVX7hg0bKiEhQfPmzVOHDh3UqVMnWSyWkh4eAAB5MlnM8m1aVWZ/T6culjVX9JRv06oymU0uHce5c+eUlJTksC0oKEgRERHKysrSzJkz1bdvXyUmJmrOnDm59vf09NSYMWM0Y8YMeXh4aPTo0Wrbtq095E+YMEExMTGqXbu2BgwYILPZrOTkZO3YsUOTJk1yaozPPvus7rjjDr355psaOHCgNm/erA8//FAffvhhoc+f6TdAKcMKOQAAd1R5QP2bJ0uzVPm++kVy/HXr1qlFixYOX7GxsWrevLmmTZumKVOmqGnTplq4cKHi4uJy7e/n56eXXnpJgwcPVvv27eXv769FixbZH4+OjtayZcu0cuVKtWnTRm3bttX06dPzVWVv06aNvvzyS/3rX/9S06ZNNXHiRL377rsaMmRIoc/fZBTFbb0AuMTx48eVkJCg1NRUqvYAgCKXmZmpgwcPqk6dOk7PE89hGFdvQHX2872yXchdsTdX9FTl++rLp0FlmUyurdKXZc6+JoR6oJSzWq32ufbBwcHMtQcAFJnChHpJ9jvFXtpxSpe2n5LtUrbMvh7ybVZVvk2rSpLLp92UdYR6oIyhag8AKGqFDfU5rr0Itrguii2LnH1NeHYBN8FcewCAu7g2wBPoix7PMOBGWNceAADkhVAPuCGq9gAA4M8I9YCbomoPACgqXHJZejj7WhDqATdH1R4A4Cqenp6SpIyMjBIeCXLkvBY5r831sPoNUIawQg4AoLCOHz+utLQ0hYSEyM/PjzXlS4hhGMrIyNDJkycVGBh40+WsCfVAGcO69gCAwjAMQydOnFBaWlpJDwWSAgMDVb169Zv+ckWoB8ooqvYAgMKwWq3Kysp9Z1gUH09PT6f/7SbUA2UYVXsAAMoHQj1QDlC1BwCgbCPUA+UEVXsAAMouQj1QzlC1BwCg7CHUA+UQVXsAAMoWQj1QjlG1BwCgbCDUA+UcVXsAANwfoR6AJKr2AAC4M0I9ADuq9gAAuCdCPYBcqNoDAOBeCPUA8kTVHgAA90GoB3BDVO0BACj9CPUAboqqPQAApRuhHoDTqNoDAFA6EeoB5AtVewAASh9CPYACoWoPAEDpQagHUGBU7QEAKB0I9QAKjao9AAAli1APwCWo2gMAUHII9QBciqo9AADFj1APwOWo2gMAULwI9QCKDFV7AACKB6EeQJGiag8AQNEj1AMoFlTtAQAoOoR6AMWGqj0AAEWDUA+g2FG1BwDAtQj1AEoEVXsAAFyHUA+gRFG1BwCg8Aj1AEocVXsAAAqHUA+g1KBqDwBAwRDqAZQqVO0BAMg/Qj2AUomqPQAAziPUAyi1qNoDAOAcQj2AUo+qPQAAN0aoB+AWqNoDAHB9hHoAboWqPQAAuRHqAbgdqvYAADgi1ANwW1TtAQC4ilAPwK1RtQcAgFAPoIygag8AKM8I9QDKDKr2AIDyilAPoMyhag8AKG8I9QDKJKr2AIDyhFAPoEyjag8AKA8I9QDKPKr2AICyjlAPoNygag8AKKsI9QDKFar2AICyiFAPoFyiag8AKEsI9QDKLar2AICyglAPoNyjag8AcHeEegAQVXsAgHsj1APAn1C1BwC4I0I9AFyDqj0AwN0Q6gHgOqjaAwDcBaEeAG6Aqj0AwB0Q6gHACVTtAQClGaEeAJxE1R4AUFoR6gEgn6jaAwBKG0I9ABQAVXsAQGlCqAeAQqBqDwAoDQj1AFBIVO0BACWNUA8ALkLVHgBQUgj1AOBCVO0BACWBUA8ARYCqPQCgOBHqAaCIULUHABQXQj0AFDGq9gCAokaoB4BiQNUeAFCUCPUAUIyo2gMAigKhHgCKGVV7AICrEeoBoIRQtQcAuAqhHgBKEFV7AIArEOoBoBSgag8AKAxCPQCUElTtAQAFRagHgFKGqj0AIL8I9QBQClG1BwDkB6EeAEoxqvYAAGcQ6gGglKNqDwC4GUI9ALgJqvYAgOsh1AOAG6FqDwDIC6EeANwQVXsAwJ8R6gHATVG1BwDkINQDgJujag8AINQDQBlA1R4AyjdCPQCUIVTtAaB8ItQDQBlD1R4Ayh9CPQCUUVTtAaD8INQDQBlG1R4AygdCPQCUA1TtAaBsI9QDQDlB1R4Ayi5CPQCUM1TtAaDsIdQDQDlE1R4AyhZCPQCUY1TtAaBsINQDQDlH1R4A3B+hHgAgiao9ALgzQj0AwI6qPQC4J0I9ACAXqvYA4F4I9QCAPFG1BwD3QagHANwQVXsAKP0I9QCAm6JqDwClG6EeAOA0qvYAUDoR6gEA+ULVHgBKH0I9AKBAqNoDQOlBqAcAFBhVewAoHQj1AIBCo2oPACWLUA8AcAmq9gBQcgj1AACXomoPAMWPUA8AcDmq9gBQvAj1AIAiQ9UeAIoHoR4AUKSo2gNA0SPUAwCKBVV7ACg6hHoAQLGhag8ARYNQDwAodlTtAcC1CPUAgBJB1R4AXIdQDwAoUVTtAaDwCPUAgBJH1R4ACodQDwAoNajaA0DBEOoBAKUKVXsAyD9CPQCgVKJqDwDOI9QDAEotqvYA4BxCPQCg1KNqDwA3RqgHALgFqvYAcH2EegCAW6FqDwC5EeoBAG6Hqj0AOCLUAwDcFlV7ALiKUA8AcGtU7QGAUA8AKCOo2gMozwj1AIAyg6o9gPKKUA8AKHOo2gMobwj1AIAyiao9gPKEUA8AKNOo2gMoDwj1AIAyj6o9gLKOUA8AKDeo2gMoqwj1AIByhao9gLKIUA8AKJeo2gMoSwj1AIByi6o9gLKCUA8AKPeo2gNwd4R6AABE1R6AeyPUAwDwJ1TtAbgjQj0AANegag/A3RDqAQC4Dqr2ANwFoR4AgBugag/AHRDqAQBwAlV7AKUZoR4AACdRtQdQWhHqAQDIJ6r2AEobQj0AAAVA1R5AaUKoBwCgEKjaAygNCPUAABQSVXsAJY1QDwCAi1C1B1BSCPUAALgQVXsAJYFQDwBAEaBqD6A4EeoBACgiVO0BFBdCPQAARYyqPYCiRqgHAKAYULUHUJQI9QAAFCOq9gCKAqEeAIBiRtUegKsR6gEAKCFU7QG4CqEeAIASRNUegCsQ6gEAKAWo2gMoDEI9AAClBFV7AAVFqAcAoJShag8gvwj1AACUQlTtAeQHoR4AgFKMqj0AZxDqAQAo5ajaA7gZQj0AAG6Cqj2A6yHUAwDgRqjaA8gLoR4AADdE1R7AnxHqAQBwU1TtAeQg1AMA4Oao2gMg1AMAUAZQtQfKN0I9AABlCFV7oHwi1AMAUMZQtQfKH0I9AABlFFV7oPwg1AMAUIZRtQfKB0I9AADlAFV7oGwj1AMAUE5QtQfKLkI9AADlDFV7oOwh1AMAUA5RtQfKFkI9AADlGFV7oGwg1AMAUM5RtQfcH6EeAABIomoPuDNCPQAAsKNqD7gnQj0AAMiFqj3gXgj1AAAgT1TtAfdBqAcAADdE1R4o/Qj1AADgpkq6am8Yhi5bL8tkMsnL7CWTyVRsxwbcAaEeAAA4rTiq9hezLmrz8c3adWaXdpzaoZ2ndurs5bP2x00yqapvVUUGR6pJUBM1CWqi1tVby8vi5dJxAO6EUA8AAPKlqKr2v539TYtSFmnpb0uVac2UxWSRzbDJUN5RxWwyyySTrIZVAV4BGthgoO6vf79q+tcs9FgAd0OoBwAABeKqqv2Bcwc06YdJ+vmPn2UxWWQ1rAUaj9lklmEY6lG7h8bfPl4hfiEF6gdwR4R6AABQYIWp2lttVi3YtUAzfpkhwzAKHOavZTFZ5GPx0SttX1Hf8L7Mv0e5QKgHAACFlt+q/YmLJzR27VjtPL2zSMZjkkmGDHW6pZOmdJoify//IjkOUFoQ6gEAgEs4W7U/cv6IRqwYodOXTrusOn89ZpNZ9QLr6aNeH6myT+UiPRZQkgj1AADApW5UtT+eflxD/jNEZzLPFHmgz2ExWRReKVzxd8UrwCugWI4JFDdCPQAAcLm8qvaVqlbSgK8H6Fj6sWIL9DksJouaBzfX36P/LouZG2eh7CHUAwCAIvPnqv2Jxie0MX2jbLKV2HjGtRmnhxo/VGLHB4oKoR4AABQpq9Wqj1d+rJknZ5b0UORp9tSX/b5UaEBoSQ8FcClzSQ8AAACUbdnK1pL0JTKXgthhM2x6deOroqaJsqbkf7oAAECZtvzgcp3IOFGi025yWA2rklOT9cvJX0p6KIBLEeoBAECRWrh7Yamo0uewmCz6155/lfQwAJdiTj0AACgy+9P2a/OJzWpTvY1qVqipc5fP6ddTv2rmLzN1+Pxhh7YmmXR/g/t1f/37FRYQpszsTKWcTdFbP7+lvWf32ts91uwxNQtupsiqkQryDdIHSR9odvLsPI9/Z9idGtF0hOoG1tXFrItad3Sdpm+drgtXLmj1/atV1bdqUZ4+UGxKz6/NAACgzMmyZalH7R766fhPmvLzFH227zO1qtZKi2MWKyIwwqHtxPYTNT5qvHad3qW4zXGa8+scnbh4QkE+QQ7tnm75tJoGNdXuM7tveOyBDQbq7c5v6/zl83r757f1+d7PdWfYnZrXa548TZ769uC3Lj9foKR4lPQAAABA2fXPXf/UNwe/UbYt275t+cHl+qLfF3qk6SN6eePLkqTo0Gj1i+inZ9Y+ozVH1tywz+jPonXs4jEFegdqw6ANebbxMHvomRbPaMuJLXps1WP27UmpSXq/+/u6r8F9+jX1VxecIVA6UKkHAABFIsuWlSvQS9KRC0e0P22/wgPD7dseavKQfk39VWuOrJFJJvl6+F6332MXj9302PUC6ynAO0DLDy132L7+v+t1MeuiosOiCfUoUwj1AACgSOxP258r0OcI8gnS2cyzkqQKnhXUrGoz7Ty9U0+3eFo/DP5Bm4ds1rf3fqvo0OgCHdvL4iVJumy9nOuxzOxMNazSUMcvHteFKxcK1D9Q2hDqAQBAkTh07lCe22PCY1StQjV7Fb1WxVoym8y6M+xO3VPvHk3bOk0vrX9JZzLP6K3Ob6l9zfb5Pvbh84dlM2y6Lfg2h+1hAWEK8g2Sr4evArwDcl2sC7gr5tQDAIAicSn7Uq5tdQLq6JXbX1HSySR9tf8rSZKfh58kqbJPZQ3+ZrC2n9ouSVp7dK2W37dcj0c+rsRjifk6dtrlNK04tEJ3R9ytA+cOaM2RNQrxC9HLt7+sLGuWPC2e8rH4KDM7s5BnCZQOhHoAAFAkrIbV4fsgnyC93+N9pV9J13PrnpPNuHozqkzr1WD93wv/tQd66eovBd8f/V4x4TGymCy5+ruZN354Qz4WH73Y5kW92OZFSdLX+7/W0QtH1TO0pzKyMpRt5D09CHA3hHoAAFAkvC3e9v/39/TX7B6zVdGzooYtH6bUS6n2x1Izrv7/6Uunc/VxJvOMPC2e8vXwVXpWer6On56VrqfXPq3qFarrFv9bdCz9mI5fPK5/3PUPnb50WheyLjiMEXBnhHoAAFAkKnlXkiR5mb00q/sshQaE6vFVj+vAuQMO7VIvpSo1I1UhfiG5+gj2C1ZmdqYuZl0s8DhOXDyhExdPSJIqelZU46DGWn149dUxelUqcL9AacKFsgAAoEg0rNJQZpNZ73R+R5HBkXrh+xeUnJqcZ9vlh5arhn8NtavRzr4t0DtQXWt11eYTm2XIcMmYnmn1jCwmixbsWiBvi7dCA0Jd0i9Q0qjUAwCAIhHiF6JXb39VXWt31dqja1XJu5JiwmMc2iw7sEyS9PH2jxUdFq1pXaZpwa4FSs9K1/3175eH2UPvbXvPYZ+Y8BjV9K8pH4uPJKlVtVZ6PPJxSVfnzB+/eFyS9EjTRxQRGKHtp7Yr28hWt1rd1P6W9pqxbYZ2nt6pyKqRspgtRf00AMXCZBiGa371BQAAuMbes3tVv3L96z7ebH4z+//f6n+rnm/9vG6vcbs8zB5KTk3Wu1vf1c7TOx32+Xv039Wmeps8+xuxfIS2/LFFktTxlo56ovkTCq8ULrPJrH1n92nBrgVaeXilPEweeqDhAxofNd4FZwmUPEI9AAAoMv/Y9Q+9/fPbLps+40ozu81Ul1pdSnoYgEswpx4AABSZu+veLQ9z6ZvtG+wbrI63dCzpYQAuQ6gHAABFJmcevcVUeuaum2XW4EaDmU+PMoVQDwAAitSghoPyfeOoomQ2mXVPxD0lPQzApQj1AACgSDUOaqy+4X1lNpV87DDJpMebP64g36CSHgrgUlwoCwAAity5y+d099K7lZaZJptsJTIGi8mi8ErhWtR3kTzNniUyBqColPyvzAAAoMyr5F1JE9tPLLFAL0mGDMV1jCPQo0wi1AMAgGLR6dZOGtFkRIkd/9XbX1WDKg1K7PhAUSLUAwCAYvNsq2c1oN6AYj/u2JZjNbDBwGI/LlBcmFMPAACKlc2w6e2f39Y/d/9TJpmK7MZUZpllk03jo8ZrSKMhRXIMoLQg1AMAgGJnGIa+PvC1Jv84WZetl12+5KXZZFYVnyqa2H6iOtzSwaV9A6URoR4AAJSYkxkn9fqm17Xx942ymCyFDvc5fdwTcY9ebPOiKnpVdNFIgdKNUA8AAEqUYRhac3SN/rnrn9ryx5YChXuzySzDMNSlVhc91PghtanepohGC5ROhHoAAFBqHEg7oEUpi7Tq8CqlXkqVdLX6bjKZlBNZTDLJJptsxtXlMW/xv0V9wvvo/vr3q3qF6iU2dqAkEeoBAECpdCbzjHaf3q1dp3cp9VKqLlsvyySTvCxeusX/FjUOaqyGVRoyxQYQoR4AAABwe6xTDwAAALg5Qj0AAADg5gj1AAAAgJsj1AMAAABujlAPAAAAuDlCPQAAAODmCPUAAACAmyPUAwAAAG6OUA8AAAC4OUI9AAAA4OYI9QAAAICbI9QDAAAAbo5QDwAAALg5Qj0AAADg5gj1AAAAgJsj1AMAAABujlAPAAAAuDlCPQAAAODmCPUAAACAmyPUAwAAAG6OUA8AAAC4OUI9AAAA4OYI9QAAAICb+/8ea9/s3lsl8gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected nodes' DataFrame rows (only '_m' columns):\n",
      "         clustering_coef_m  degree_centrality_m  degree_m  \\\n",
      "node_id                                                     \n",
      "2619                   0.0             0.000369         1   \n",
      "2618                   0.0             0.000369         1   \n",
      "\n",
      "         neighbor_labels_avg_m  \n",
      "node_id                         \n",
      "2619                       2.0  \n",
      "2618                       2.0  \n"
     ]
    }
   ],
   "source": [
    "def show_random_node_and_neighbors_with_labels(data, df, seed=None):\n",
    "    \"\"\"\n",
    "    Randomly selects one node, displays it and all its neighbors with node labels,\n",
    "    colors nodes by label, and prints their corresponding rows from the DataFrame (only columns ending with '_m').\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.colors as mcolors\n",
    "    import numpy as np\n",
    "\n",
    "    G = to_networkx(data, to_undirected=True)\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    \n",
    "    # Select a random node with at least one neighbor\n",
    "    nodes_with_neighbors = [n for n in G.nodes() if len(list(G.neighbors(n))) > 0]\n",
    "    if not nodes_with_neighbors:\n",
    "        print(\"No nodes with neighbors found.\")\n",
    "        return\n",
    "    \n",
    "    selected_node = random.choice(nodes_with_neighbors)\n",
    "    neighbors = list(G.neighbors(selected_node))\n",
    "    selected_nodes = [selected_node] + neighbors\n",
    "\n",
    "    # Subgraph for visualization\n",
    "    subG = G.subgraph(selected_nodes)\n",
    "    \n",
    "    # Get labels for the selected nodes\n",
    "    node_labels = df.loc[selected_nodes, 'label'].to_dict()\n",
    "    labels_unique = sorted(df['label'].unique())\n",
    "    cmap = plt.get_cmap('tab10' if len(labels_unique) <= 10 else 'tab20')\n",
    "    label_to_color = {label: cmap(i % cmap.N) for i, label in enumerate(labels_unique)}\n",
    "    node_colors = [label_to_color[node_labels[n]] for n in subG.nodes]\n",
    "\n",
    "    # Draw the subgraph\n",
    "    pos = nx.spring_layout(subG, seed=seed)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    nx.draw(subG, pos, with_labels=True, node_color=node_colors, edge_color='gray', node_size=800, font_color='white')\n",
    "    # Only show node id as label to avoid overlap\n",
    "    plt.title(f\"Random node {selected_node} and its neighbors (colored by label)\")\n",
    "    # Legend\n",
    "    handles = [plt.Line2D([0], [0], marker='o', color='w', label=f\"Label {l}\", \n",
    "                          markerfacecolor=label_to_color[l], markersize=10) for l in labels_unique]\n",
    "    plt.legend(handles=handles, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print the corresponding rows from the DataFrame (only columns ending with '_m')\n",
    "    cols_m = [col for col in df.columns if col.endswith('_m')]\n",
    "    print(\"Selected nodes' DataFrame rows (only '_m' columns):\")\n",
    "    print(df.loc[selected_nodes, cols_m])\n",
    "\n",
    "\n",
    "show_random_node_and_neighbors_with_labels(data_cora, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5dd9c9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clustering_coef_m', 'degree_centrality_m', 'degree_m', 'neighbor_labels_avg_m']\n",
      "Splitting data into train and test sets...\n",
      "Training Random Forest with default parameters...\n",
      "Predicting on test set...\n",
      "Test accuracy: 0.7343\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.53      0.56        70\n",
      "           1       0.63      0.72      0.67        43\n",
      "           2       0.77      0.81      0.79        84\n",
      "           3       0.76      0.84      0.80       164\n",
      "           4       0.79      0.72      0.75        85\n",
      "           5       0.75      0.67      0.71        60\n",
      "           6       0.72      0.64      0.68        36\n",
      "\n",
      "    accuracy                           0.73       542\n",
      "   macro avg       0.72      0.70      0.71       542\n",
      "weighted avg       0.73      0.73      0.73       542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Features and labels\n",
    "X = df[[col for col in df.columns if col.endswith('_m')]]\n",
    "print(X.columns.tolist())\n",
    "y = df['label']\n",
    "\n",
    "print(\"Splitting data into train and test sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "use_param_search = False  # Set to False to skip parameter search\n",
    "\n",
    "if use_param_search:\n",
    "    print(\"Starting hyperparameter tuning with GridSearchCV...\")\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5]\n",
    "    }\n",
    "    grid = GridSearchCV(\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        param_grid,\n",
    "        cv=3,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(\"Best parameters found:\", grid.best_params_)\n",
    "    best_rf = grid.best_estimator_\n",
    "else:\n",
    "    print(\"Training Random Forest with default parameters...\")\n",
    "    best_rf = RandomForestClassifier(random_state=42)\n",
    "    best_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Predicting on test set...\")\n",
    "y_pred = best_rf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test accuracy: {acc:.4f}\")\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cea67b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               feature  importance\n",
      "0    clustering_coef_m    0.614208\n",
      "1  degree_centrality_m    0.385792\n"
     ]
    }
   ],
   "source": [
    "importances = best_rf.feature_importances_\n",
    "importances_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(importances_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6472c372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_1426</th>\n",
       "      <th>feat_1427</th>\n",
       "      <th>feat_1428</th>\n",
       "      <th>feat_1429</th>\n",
       "      <th>feat_1430</th>\n",
       "      <th>feat_1431</th>\n",
       "      <th>feat_1432</th>\n",
       "      <th>label</th>\n",
       "      <th>clustering_coef_m</th>\n",
       "      <th>degree_centrality_m</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.001108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.001847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.001478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2708 rows × 1436 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feat_0  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  \\\n",
       "node_id                                                                   \n",
       "0           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4           0.0     0.0     0.0     1.0     0.0     0.0     0.0     0.0   \n",
       "...         ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "2703        0.0     0.0     0.0     0.0     0.0     1.0     0.0     0.0   \n",
       "2704        0.0     0.0     1.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2705        0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2706        0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2707        0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "         feat_8  feat_9  ...  feat_1426  feat_1427  feat_1428  feat_1429  \\\n",
       "node_id                  ...                                               \n",
       "0           0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
       "1           0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
       "2           0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
       "3           0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
       "4           0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
       "...         ...     ...  ...        ...        ...        ...        ...   \n",
       "2703        0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
       "2704        0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
       "2705        0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
       "2706        0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
       "2707        0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
       "\n",
       "         feat_1430  feat_1431  feat_1432  label  clustering_coef_m  \\\n",
       "node_id                                                              \n",
       "0              0.0        0.0        0.0      3           0.333333   \n",
       "1              0.0        0.0        0.0      4           0.000000   \n",
       "2              0.0        0.0        0.0      4           0.000000   \n",
       "3              0.0        0.0        0.0      0           0.000000   \n",
       "4              0.0        0.0        0.0      3           0.700000   \n",
       "...            ...        ...        ...    ...                ...   \n",
       "2703           0.0        0.0        0.0      3           0.000000   \n",
       "2704           0.0        0.0        0.0      3           0.000000   \n",
       "2705           0.0        0.0        0.0      3           0.000000   \n",
       "2706           0.0        0.0        0.0      3           0.500000   \n",
       "2707           0.0        0.0        0.0      3           0.833333   \n",
       "\n",
       "         degree_centrality_m  \n",
       "node_id                       \n",
       "0                   0.001108  \n",
       "1                   0.001108  \n",
       "2                   0.001847  \n",
       "3                   0.000369  \n",
       "4                   0.001847  \n",
       "...                      ...  \n",
       "2703                0.000369  \n",
       "2704                0.000369  \n",
       "2705                0.000369  \n",
       "2706                0.001478  \n",
       "2707                0.001478  \n",
       "\n",
       "[2708 rows x 1436 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b414cf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feat_0', 'feat_1', 'feat_2', 'feat_3', 'feat_4', 'feat_5', 'feat_6', 'feat_7', 'feat_8', 'feat_9', 'feat_10', 'feat_11', 'feat_12', 'feat_13', 'feat_14', 'feat_15', 'feat_16', 'feat_17', 'feat_18', 'feat_19', 'feat_20', 'feat_21', 'feat_22', 'feat_23', 'feat_24', 'feat_25', 'feat_26', 'feat_27', 'feat_28', 'feat_29', 'feat_30', 'feat_31', 'feat_32', 'feat_33', 'feat_34', 'feat_35', 'feat_36', 'feat_37', 'feat_38', 'feat_39', 'feat_40', 'feat_41', 'feat_42', 'feat_43', 'feat_44', 'feat_45', 'feat_46', 'feat_47', 'feat_48', 'feat_49', 'feat_50', 'feat_51', 'feat_52', 'feat_53', 'feat_54', 'feat_55', 'feat_56', 'feat_57', 'feat_58', 'feat_59', 'feat_60', 'feat_61', 'feat_62', 'feat_63', 'feat_64', 'feat_65', 'feat_66', 'feat_67', 'feat_68', 'feat_69', 'feat_70', 'feat_71', 'feat_72', 'feat_73', 'feat_74', 'feat_75', 'feat_76', 'feat_77', 'feat_78', 'feat_79', 'feat_80', 'feat_81', 'feat_82', 'feat_83', 'feat_84', 'feat_85', 'feat_86', 'feat_87', 'feat_88', 'feat_89', 'feat_90', 'feat_91', 'feat_92', 'feat_93', 'feat_94', 'feat_95', 'feat_96', 'feat_97', 'feat_98', 'feat_99', 'feat_100', 'feat_101', 'feat_102', 'feat_103', 'feat_104', 'feat_105', 'feat_106', 'feat_107', 'feat_108', 'feat_109', 'feat_110', 'feat_111', 'feat_112', 'feat_113', 'feat_114', 'feat_115', 'feat_116', 'feat_117', 'feat_118', 'feat_119', 'feat_120', 'feat_121', 'feat_122', 'feat_123', 'feat_124', 'feat_125', 'feat_126', 'feat_127', 'feat_128', 'feat_129', 'feat_130', 'feat_131', 'feat_132', 'feat_133', 'feat_134', 'feat_135', 'feat_136', 'feat_137', 'feat_138', 'feat_139', 'feat_140', 'feat_141', 'feat_142', 'feat_143', 'feat_144', 'feat_145', 'feat_146', 'feat_147', 'feat_148', 'feat_149', 'feat_150', 'feat_151', 'feat_152', 'feat_153', 'feat_154', 'feat_155', 'feat_156', 'feat_157', 'feat_158', 'feat_159', 'feat_160', 'feat_161', 'feat_162', 'feat_163', 'feat_164', 'feat_165', 'feat_166', 'feat_167', 'feat_168', 'feat_169', 'feat_170', 'feat_171', 'feat_172', 'feat_173', 'feat_174', 'feat_175', 'feat_176', 'feat_177', 'feat_178', 'feat_179', 'feat_180', 'feat_181', 'feat_182', 'feat_183', 'feat_184', 'feat_185', 'feat_186', 'feat_187', 'feat_188', 'feat_189', 'feat_190', 'feat_191', 'feat_192', 'feat_193', 'feat_194', 'feat_195', 'feat_196', 'feat_197', 'feat_198', 'feat_199', 'feat_200', 'feat_201', 'feat_202', 'feat_203', 'feat_204', 'feat_205', 'feat_206', 'feat_207', 'feat_208', 'feat_209', 'feat_210', 'feat_211', 'feat_212', 'feat_213', 'feat_214', 'feat_215', 'feat_216', 'feat_217', 'feat_218', 'feat_219', 'feat_220', 'feat_221', 'feat_222', 'feat_223', 'feat_224', 'feat_225', 'feat_226', 'feat_227', 'feat_228', 'feat_229', 'feat_230', 'feat_231', 'feat_232', 'feat_233', 'feat_234', 'feat_235', 'feat_236', 'feat_237', 'feat_238', 'feat_239', 'feat_240', 'feat_241', 'feat_242', 'feat_243', 'feat_244', 'feat_245', 'feat_246', 'feat_247', 'feat_248', 'feat_249', 'feat_250', 'feat_251', 'feat_252', 'feat_253', 'feat_254', 'feat_255', 'feat_256', 'feat_257', 'feat_258', 'feat_259', 'feat_260', 'feat_261', 'feat_262', 'feat_263', 'feat_264', 'feat_265', 'feat_266', 'feat_267', 'feat_268', 'feat_269', 'feat_270', 'feat_271', 'feat_272', 'feat_273', 'feat_274', 'feat_275', 'feat_276', 'feat_277', 'feat_278', 'feat_279', 'feat_280', 'feat_281', 'feat_282', 'feat_283', 'feat_284', 'feat_285', 'feat_286', 'feat_287', 'feat_288', 'feat_289', 'feat_290', 'feat_291', 'feat_292', 'feat_293', 'feat_294', 'feat_295', 'feat_296', 'feat_297', 'feat_298', 'feat_299', 'feat_300', 'feat_301', 'feat_302', 'feat_303', 'feat_304', 'feat_305', 'feat_306', 'feat_307', 'feat_308', 'feat_309', 'feat_310', 'feat_311', 'feat_312', 'feat_313', 'feat_314', 'feat_315', 'feat_316', 'feat_317', 'feat_318', 'feat_319', 'feat_320', 'feat_321', 'feat_322', 'feat_323', 'feat_324', 'feat_325', 'feat_326', 'feat_327', 'feat_328', 'feat_329', 'feat_330', 'feat_331', 'feat_332', 'feat_333', 'feat_334', 'feat_335', 'feat_336', 'feat_337', 'feat_338', 'feat_339', 'feat_340', 'feat_341', 'feat_342', 'feat_343', 'feat_344', 'feat_345', 'feat_346', 'feat_347', 'feat_348', 'feat_349', 'feat_350', 'feat_351', 'feat_352', 'feat_353', 'feat_354', 'feat_355', 'feat_356', 'feat_357', 'feat_358', 'feat_359', 'feat_360', 'feat_361', 'feat_362', 'feat_363', 'feat_364', 'feat_365', 'feat_366', 'feat_367', 'feat_368', 'feat_369', 'feat_370', 'feat_371', 'feat_372', 'feat_373', 'feat_374', 'feat_375', 'feat_376', 'feat_377', 'feat_378', 'feat_379', 'feat_380', 'feat_381', 'feat_382', 'feat_383', 'feat_384', 'feat_385', 'feat_386', 'feat_387', 'feat_388', 'feat_389', 'feat_390', 'feat_391', 'feat_392', 'feat_393', 'feat_394', 'feat_395', 'feat_396', 'feat_397', 'feat_398', 'feat_399', 'feat_400', 'feat_401', 'feat_402', 'feat_403', 'feat_404', 'feat_405', 'feat_406', 'feat_407', 'feat_408', 'feat_409', 'feat_410', 'feat_411', 'feat_412', 'feat_413', 'feat_414', 'feat_415', 'feat_416', 'feat_417', 'feat_418', 'feat_419', 'feat_420', 'feat_421', 'feat_422', 'feat_423', 'feat_424', 'feat_425', 'feat_426', 'feat_427', 'feat_428', 'feat_429', 'feat_430', 'feat_431', 'feat_432', 'feat_433', 'feat_434', 'feat_435', 'feat_436', 'feat_437', 'feat_438', 'feat_439', 'feat_440', 'feat_441', 'feat_442', 'feat_443', 'feat_444', 'feat_445', 'feat_446', 'feat_447', 'feat_448', 'feat_449', 'feat_450', 'feat_451', 'feat_452', 'feat_453', 'feat_454', 'feat_455', 'feat_456', 'feat_457', 'feat_458', 'feat_459', 'feat_460', 'feat_461', 'feat_462', 'feat_463', 'feat_464', 'feat_465', 'feat_466', 'feat_467', 'feat_468', 'feat_469', 'feat_470', 'feat_471', 'feat_472', 'feat_473', 'feat_474', 'feat_475', 'feat_476', 'feat_477', 'feat_478', 'feat_479', 'feat_480', 'feat_481', 'feat_482', 'feat_483', 'feat_484', 'feat_485', 'feat_486', 'feat_487', 'feat_488', 'feat_489', 'feat_490', 'feat_491', 'feat_492', 'feat_493', 'feat_494', 'feat_495', 'feat_496', 'feat_497', 'feat_498', 'feat_499', 'feat_500', 'feat_501', 'feat_502', 'feat_503', 'feat_504', 'feat_505', 'feat_506', 'feat_507', 'feat_508', 'feat_509', 'feat_510', 'feat_511', 'feat_512', 'feat_513', 'feat_514', 'feat_515', 'feat_516', 'feat_517', 'feat_518', 'feat_519', 'feat_520', 'feat_521', 'feat_522', 'feat_523', 'feat_524', 'feat_525', 'feat_526', 'feat_527', 'feat_528', 'feat_529', 'feat_530', 'feat_531', 'feat_532', 'feat_533', 'feat_534', 'feat_535', 'feat_536', 'feat_537', 'feat_538', 'feat_539', 'feat_540', 'feat_541', 'feat_542', 'feat_543', 'feat_544', 'feat_545', 'feat_546', 'feat_547', 'feat_548', 'feat_549', 'feat_550', 'feat_551', 'feat_552', 'feat_553', 'feat_554', 'feat_555', 'feat_556', 'feat_557', 'feat_558', 'feat_559', 'feat_560', 'feat_561', 'feat_562', 'feat_563', 'feat_564', 'feat_565', 'feat_566', 'feat_567', 'feat_568', 'feat_569', 'feat_570', 'feat_571', 'feat_572', 'feat_573', 'feat_574', 'feat_575', 'feat_576', 'feat_577', 'feat_578', 'feat_579', 'feat_580', 'feat_581', 'feat_582', 'feat_583', 'feat_584', 'feat_585', 'feat_586', 'feat_587', 'feat_588', 'feat_589', 'feat_590', 'feat_591', 'feat_592', 'feat_593', 'feat_594', 'feat_595', 'feat_596', 'feat_597', 'feat_598', 'feat_599', 'feat_600', 'feat_601', 'feat_602', 'feat_603', 'feat_604', 'feat_605', 'feat_606', 'feat_607', 'feat_608', 'feat_609', 'feat_610', 'feat_611', 'feat_612', 'feat_613', 'feat_614', 'feat_615', 'feat_616', 'feat_617', 'feat_618', 'feat_619', 'feat_620', 'feat_621', 'feat_622', 'feat_623', 'feat_624', 'feat_625', 'feat_626', 'feat_627', 'feat_628', 'feat_629', 'feat_630', 'feat_631', 'feat_632', 'feat_633', 'feat_634', 'feat_635', 'feat_636', 'feat_637', 'feat_638', 'feat_639', 'feat_640', 'feat_641', 'feat_642', 'feat_643', 'feat_644', 'feat_645', 'feat_646', 'feat_647', 'feat_648', 'feat_649', 'feat_650', 'feat_651', 'feat_652', 'feat_653', 'feat_654', 'feat_655', 'feat_656', 'feat_657', 'feat_658', 'feat_659', 'feat_660', 'feat_661', 'feat_662', 'feat_663', 'feat_664', 'feat_665', 'feat_666', 'feat_667', 'feat_668', 'feat_669', 'feat_670', 'feat_671', 'feat_672', 'feat_673', 'feat_674', 'feat_675', 'feat_676', 'feat_677', 'feat_678', 'feat_679', 'feat_680', 'feat_681', 'feat_682', 'feat_683', 'feat_684', 'feat_685', 'feat_686', 'feat_687', 'feat_688', 'feat_689', 'feat_690', 'feat_691', 'feat_692', 'feat_693', 'feat_694', 'feat_695', 'feat_696', 'feat_697', 'feat_698', 'feat_699', 'feat_700', 'feat_701', 'feat_702', 'feat_703', 'feat_704', 'feat_705', 'feat_706', 'feat_707', 'feat_708', 'feat_709', 'feat_710', 'feat_711', 'feat_712', 'feat_713', 'feat_714', 'feat_715', 'feat_716', 'feat_717', 'feat_718', 'feat_719', 'feat_720', 'feat_721', 'feat_722', 'feat_723', 'feat_724', 'feat_725', 'feat_726', 'feat_727', 'feat_728', 'feat_729', 'feat_730', 'feat_731', 'feat_732', 'feat_733', 'feat_734', 'feat_735', 'feat_736', 'feat_737', 'feat_738', 'feat_739', 'feat_740', 'feat_741', 'feat_742', 'feat_743', 'feat_744', 'feat_745', 'feat_746', 'feat_747', 'feat_748', 'feat_749', 'feat_750', 'feat_751', 'feat_752', 'feat_753', 'feat_754', 'feat_755', 'feat_756', 'feat_757', 'feat_758', 'feat_759', 'feat_760', 'feat_761', 'feat_762', 'feat_763', 'feat_764', 'feat_765', 'feat_766', 'feat_767', 'feat_768', 'feat_769', 'feat_770', 'feat_771', 'feat_772', 'feat_773', 'feat_774', 'feat_775', 'feat_776', 'feat_777', 'feat_778', 'feat_779', 'feat_780', 'feat_781', 'feat_782', 'feat_783', 'feat_784', 'feat_785', 'feat_786', 'feat_787', 'feat_788', 'feat_789', 'feat_790', 'feat_791', 'feat_792', 'feat_793', 'feat_794', 'feat_795', 'feat_796', 'feat_797', 'feat_798', 'feat_799', 'feat_800', 'feat_801', 'feat_802', 'feat_803', 'feat_804', 'feat_805', 'feat_806', 'feat_807', 'feat_808', 'feat_809', 'feat_810', 'feat_811', 'feat_812', 'feat_813', 'feat_814', 'feat_815', 'feat_816', 'feat_817', 'feat_818', 'feat_819', 'feat_820', 'feat_821', 'feat_822', 'feat_823', 'feat_824', 'feat_825', 'feat_826', 'feat_827', 'feat_828', 'feat_829', 'feat_830', 'feat_831', 'feat_832', 'feat_833', 'feat_834', 'feat_835', 'feat_836', 'feat_837', 'feat_838', 'feat_839', 'feat_840', 'feat_841', 'feat_842', 'feat_843', 'feat_844', 'feat_845', 'feat_846', 'feat_847', 'feat_848', 'feat_849', 'feat_850', 'feat_851', 'feat_852', 'feat_853', 'feat_854', 'feat_855', 'feat_856', 'feat_857', 'feat_858', 'feat_859', 'feat_860', 'feat_861', 'feat_862', 'feat_863', 'feat_864', 'feat_865', 'feat_866', 'feat_867', 'feat_868', 'feat_869', 'feat_870', 'feat_871', 'feat_872', 'feat_873', 'feat_874', 'feat_875', 'feat_876', 'feat_877', 'feat_878', 'feat_879', 'feat_880', 'feat_881', 'feat_882', 'feat_883', 'feat_884', 'feat_885', 'feat_886', 'feat_887', 'feat_888', 'feat_889', 'feat_890', 'feat_891', 'feat_892', 'feat_893', 'feat_894', 'feat_895', 'feat_896', 'feat_897', 'feat_898', 'feat_899', 'feat_900', 'feat_901', 'feat_902', 'feat_903', 'feat_904', 'feat_905', 'feat_906', 'feat_907', 'feat_908', 'feat_909', 'feat_910', 'feat_911', 'feat_912', 'feat_913', 'feat_914', 'feat_915', 'feat_916', 'feat_917', 'feat_918', 'feat_919', 'feat_920', 'feat_921', 'feat_922', 'feat_923', 'feat_924', 'feat_925', 'feat_926', 'feat_927', 'feat_928', 'feat_929', 'feat_930', 'feat_931', 'feat_932', 'feat_933', 'feat_934', 'feat_935', 'feat_936', 'feat_937', 'feat_938', 'feat_939', 'feat_940', 'feat_941', 'feat_942', 'feat_943', 'feat_944', 'feat_945', 'feat_946', 'feat_947', 'feat_948', 'feat_949', 'feat_950', 'feat_951', 'feat_952', 'feat_953', 'feat_954', 'feat_955', 'feat_956', 'feat_957', 'feat_958', 'feat_959', 'feat_960', 'feat_961', 'feat_962', 'feat_963', 'feat_964', 'feat_965', 'feat_966', 'feat_967', 'feat_968', 'feat_969', 'feat_970', 'feat_971', 'feat_972', 'feat_973', 'feat_974', 'feat_975', 'feat_976', 'feat_977', 'feat_978', 'feat_979', 'feat_980', 'feat_981', 'feat_982', 'feat_983', 'feat_984', 'feat_985', 'feat_986', 'feat_987', 'feat_988', 'feat_989', 'feat_990', 'feat_991', 'feat_992', 'feat_993', 'feat_994', 'feat_995', 'feat_996', 'feat_997', 'feat_998', 'feat_999', 'feat_1000', 'feat_1001', 'feat_1002', 'feat_1003', 'feat_1004', 'feat_1005', 'feat_1006', 'feat_1007', 'feat_1008', 'feat_1009', 'feat_1010', 'feat_1011', 'feat_1012', 'feat_1013', 'feat_1014', 'feat_1015', 'feat_1016', 'feat_1017', 'feat_1018', 'feat_1019', 'feat_1020', 'feat_1021', 'feat_1022', 'feat_1023', 'feat_1024', 'feat_1025', 'feat_1026', 'feat_1027', 'feat_1028', 'feat_1029', 'feat_1030', 'feat_1031', 'feat_1032', 'feat_1033', 'feat_1034', 'feat_1035', 'feat_1036', 'feat_1037', 'feat_1038', 'feat_1039', 'feat_1040', 'feat_1041', 'feat_1042', 'feat_1043', 'feat_1044', 'feat_1045', 'feat_1046', 'feat_1047', 'feat_1048', 'feat_1049', 'feat_1050', 'feat_1051', 'feat_1052', 'feat_1053', 'feat_1054', 'feat_1055', 'feat_1056', 'feat_1057', 'feat_1058', 'feat_1059', 'feat_1060', 'feat_1061', 'feat_1062', 'feat_1063', 'feat_1064', 'feat_1065', 'feat_1066', 'feat_1067', 'feat_1068', 'feat_1069', 'feat_1070', 'feat_1071', 'feat_1072', 'feat_1073', 'feat_1074', 'feat_1075', 'feat_1076', 'feat_1077', 'feat_1078', 'feat_1079', 'feat_1080', 'feat_1081', 'feat_1082', 'feat_1083', 'feat_1084', 'feat_1085', 'feat_1086', 'feat_1087', 'feat_1088', 'feat_1089', 'feat_1090', 'feat_1091', 'feat_1092', 'feat_1093', 'feat_1094', 'feat_1095', 'feat_1096', 'feat_1097', 'feat_1098', 'feat_1099', 'feat_1100', 'feat_1101', 'feat_1102', 'feat_1103', 'feat_1104', 'feat_1105', 'feat_1106', 'feat_1107', 'feat_1108', 'feat_1109', 'feat_1110', 'feat_1111', 'feat_1112', 'feat_1113', 'feat_1114', 'feat_1115', 'feat_1116', 'feat_1117', 'feat_1118', 'feat_1119', 'feat_1120', 'feat_1121', 'feat_1122', 'feat_1123', 'feat_1124', 'feat_1125', 'feat_1126', 'feat_1127', 'feat_1128', 'feat_1129', 'feat_1130', 'feat_1131', 'feat_1132', 'feat_1133', 'feat_1134', 'feat_1135', 'feat_1136', 'feat_1137', 'feat_1138', 'feat_1139', 'feat_1140', 'feat_1141', 'feat_1142', 'feat_1143', 'feat_1144', 'feat_1145', 'feat_1146', 'feat_1147', 'feat_1148', 'feat_1149', 'feat_1150', 'feat_1151', 'feat_1152', 'feat_1153', 'feat_1154', 'feat_1155', 'feat_1156', 'feat_1157', 'feat_1158', 'feat_1159', 'feat_1160', 'feat_1161', 'feat_1162', 'feat_1163', 'feat_1164', 'feat_1165', 'feat_1166', 'feat_1167', 'feat_1168', 'feat_1169', 'feat_1170', 'feat_1171', 'feat_1172', 'feat_1173', 'feat_1174', 'feat_1175', 'feat_1176', 'feat_1177', 'feat_1178', 'feat_1179', 'feat_1180', 'feat_1181', 'feat_1182', 'feat_1183', 'feat_1184', 'feat_1185', 'feat_1186', 'feat_1187', 'feat_1188', 'feat_1189', 'feat_1190', 'feat_1191', 'feat_1192', 'feat_1193', 'feat_1194', 'feat_1195', 'feat_1196', 'feat_1197', 'feat_1198', 'feat_1199', 'feat_1200', 'feat_1201', 'feat_1202', 'feat_1203', 'feat_1204', 'feat_1205', 'feat_1206', 'feat_1207', 'feat_1208', 'feat_1209', 'feat_1210', 'feat_1211', 'feat_1212', 'feat_1213', 'feat_1214', 'feat_1215', 'feat_1216', 'feat_1217', 'feat_1218', 'feat_1219', 'feat_1220', 'feat_1221', 'feat_1222', 'feat_1223', 'feat_1224', 'feat_1225', 'feat_1226', 'feat_1227', 'feat_1228', 'feat_1229', 'feat_1230', 'feat_1231', 'feat_1232', 'feat_1233', 'feat_1234', 'feat_1235', 'feat_1236', 'feat_1237', 'feat_1238', 'feat_1239', 'feat_1240', 'feat_1241', 'feat_1242', 'feat_1243', 'feat_1244', 'feat_1245', 'feat_1246', 'feat_1247', 'feat_1248', 'feat_1249', 'feat_1250', 'feat_1251', 'feat_1252', 'feat_1253', 'feat_1254', 'feat_1255', 'feat_1256', 'feat_1257', 'feat_1258', 'feat_1259', 'feat_1260', 'feat_1261', 'feat_1262', 'feat_1263', 'feat_1264', 'feat_1265', 'feat_1266', 'feat_1267', 'feat_1268', 'feat_1269', 'feat_1270', 'feat_1271', 'feat_1272', 'feat_1273', 'feat_1274', 'feat_1275', 'feat_1276', 'feat_1277', 'feat_1278', 'feat_1279', 'feat_1280', 'feat_1281', 'feat_1282', 'feat_1283', 'feat_1284', 'feat_1285', 'feat_1286', 'feat_1287', 'feat_1288', 'feat_1289', 'feat_1290', 'feat_1291', 'feat_1292', 'feat_1293', 'feat_1294', 'feat_1295', 'feat_1296', 'feat_1297', 'feat_1298', 'feat_1299', 'feat_1300', 'feat_1301', 'feat_1302', 'feat_1303', 'feat_1304', 'feat_1305', 'feat_1306', 'feat_1307', 'feat_1308', 'feat_1309', 'feat_1310', 'feat_1311', 'feat_1312', 'feat_1313', 'feat_1314', 'feat_1315', 'feat_1316', 'feat_1317', 'feat_1318', 'feat_1319', 'feat_1320', 'feat_1321', 'feat_1322', 'feat_1323', 'feat_1324', 'feat_1325', 'feat_1326', 'feat_1327', 'feat_1328', 'feat_1329', 'feat_1330', 'feat_1331', 'feat_1332', 'feat_1333', 'feat_1334', 'feat_1335', 'feat_1336', 'feat_1337', 'feat_1338', 'feat_1339', 'feat_1340', 'feat_1341', 'feat_1342', 'feat_1343', 'feat_1344', 'feat_1345', 'feat_1346', 'feat_1347', 'feat_1348', 'feat_1349', 'feat_1350', 'feat_1351', 'feat_1352', 'feat_1353', 'feat_1354', 'feat_1355', 'feat_1356', 'feat_1357', 'feat_1358', 'feat_1359', 'feat_1360', 'feat_1361', 'feat_1362', 'feat_1363', 'feat_1364', 'feat_1365', 'feat_1366', 'feat_1367', 'feat_1368', 'feat_1369', 'feat_1370', 'feat_1371', 'feat_1372', 'feat_1373', 'feat_1374', 'feat_1375', 'feat_1376', 'feat_1377', 'feat_1378', 'feat_1379', 'feat_1380', 'feat_1381', 'feat_1382', 'feat_1383', 'feat_1384', 'feat_1385', 'feat_1386', 'feat_1387', 'feat_1388', 'feat_1389', 'feat_1390', 'feat_1391', 'feat_1392', 'feat_1393', 'feat_1394', 'feat_1395', 'feat_1396', 'feat_1397', 'feat_1398', 'feat_1399', 'feat_1400', 'feat_1401', 'feat_1402', 'feat_1403', 'feat_1404', 'feat_1405', 'feat_1406', 'feat_1407', 'feat_1408', 'feat_1409', 'feat_1410', 'feat_1411', 'feat_1412', 'feat_1413', 'feat_1414', 'feat_1415', 'feat_1416', 'feat_1417', 'feat_1418', 'feat_1419', 'feat_1420', 'feat_1421', 'feat_1422', 'feat_1423', 'feat_1424', 'feat_1425', 'feat_1426', 'feat_1427', 'feat_1428', 'feat_1429', 'feat_1430', 'feat_1431', 'feat_1432', 'clustering_coef_m', 'degree_centrality_m', 'degree_m', 'neighbor_labels_avg_m']\n",
      "Splitting data into train and test sets...\n",
      "\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Test accuracy: 0.8100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.74        70\n",
      "           1       0.91      0.74      0.82        43\n",
      "           2       0.89      0.85      0.87        84\n",
      "           3       0.80      0.88      0.84       164\n",
      "           4       0.89      0.79      0.84        85\n",
      "           5       0.69      0.85      0.76        60\n",
      "           6       0.79      0.61      0.69        36\n",
      "\n",
      "    accuracy                           0.81       542\n",
      "   macro avg       0.82      0.78      0.79       542\n",
      "weighted avg       0.82      0.81      0.81       542\n",
      "\n",
      "\n",
      "Training SVM...\n",
      "SVM Test accuracy: 0.8044\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.73      0.69        70\n",
      "           1       0.97      0.65      0.78        43\n",
      "           2       0.89      0.88      0.89        84\n",
      "           3       0.77      0.90      0.83       164\n",
      "           4       0.88      0.81      0.85        85\n",
      "           5       0.76      0.75      0.76        60\n",
      "           6       0.88      0.58      0.70        36\n",
      "\n",
      "    accuracy                           0.80       542\n",
      "   macro avg       0.83      0.76      0.78       542\n",
      "weighted avg       0.81      0.80      0.80       542\n",
      "\n",
      "\n",
      "Training KNN...\n",
      "KNN Test accuracy: 0.6144\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.56      0.60        70\n",
      "           1       0.50      0.37      0.43        43\n",
      "           2       0.57      0.85      0.68        84\n",
      "           3       0.69      0.73      0.71       164\n",
      "           4       0.58      0.54      0.56        85\n",
      "           5       0.56      0.57      0.56        60\n",
      "           6       0.70      0.19      0.30        36\n",
      "\n",
      "    accuracy                           0.61       542\n",
      "   macro avg       0.61      0.54      0.55       542\n",
      "weighted avg       0.62      0.61      0.60       542\n",
      "\n",
      "\n",
      "Training Decision Tree...\n",
      "Decision Tree Test accuracy: 0.7528\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.56      0.57        70\n",
      "           1       0.66      0.72      0.69        43\n",
      "           2       0.92      0.86      0.89        84\n",
      "           3       0.78      0.84      0.81       164\n",
      "           4       0.80      0.72      0.76        85\n",
      "           5       0.69      0.73      0.71        60\n",
      "           6       0.69      0.67      0.68        36\n",
      "\n",
      "    accuracy                           0.75       542\n",
      "   macro avg       0.73      0.73      0.73       542\n",
      "weighted avg       0.75      0.75      0.75       542\n",
      "\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Test accuracy: 0.8303\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.76        70\n",
      "           1       0.94      0.74      0.83        43\n",
      "           2       0.92      0.90      0.91        84\n",
      "           3       0.81      0.90      0.85       164\n",
      "           4       0.86      0.84      0.85        85\n",
      "           5       0.77      0.78      0.78        60\n",
      "           6       0.88      0.61      0.72        36\n",
      "\n",
      "    accuracy                           0.83       542\n",
      "   macro avg       0.84      0.79      0.81       542\n",
      "weighted avg       0.83      0.83      0.83       542\n",
      "\n",
      "\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Test accuracy: 0.8192\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.67      0.72        70\n",
      "           1       0.76      0.74      0.75        43\n",
      "           2       0.86      0.89      0.88        84\n",
      "           3       0.81      0.88      0.84       164\n",
      "           4       0.85      0.81      0.83        85\n",
      "           5       0.79      0.82      0.80        60\n",
      "           6       0.93      0.75      0.83        36\n",
      "\n",
      "    accuracy                           0.82       542\n",
      "   macro avg       0.82      0.80      0.81       542\n",
      "weighted avg       0.82      0.82      0.82       542\n",
      "\n",
      "\n",
      "Training MLP...\n",
      "MLP Test accuracy: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.76        70\n",
      "           1       0.89      0.74      0.81        43\n",
      "           2       0.85      0.86      0.85        84\n",
      "           3       0.79      0.87      0.83       164\n",
      "           4       0.89      0.79      0.84        85\n",
      "           5       0.68      0.77      0.72        60\n",
      "           6       0.71      0.56      0.62        36\n",
      "\n",
      "    accuracy                           0.80       542\n",
      "   macro avg       0.80      0.76      0.78       542\n",
      "weighted avg       0.80      0.80      0.80       542\n",
      "\n",
      "\n",
      "Summary of test accuracies:\n",
      "Logistic Regression: 0.8100\n",
      "SVM: 0.8044\n",
      "KNN: 0.6144\n",
      "Decision Tree: 0.7528\n",
      "Random Forest: 0.8303\n",
      "Gradient Boosting: 0.8192\n",
      "MLP: 0.7989\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Features and labels\n",
    "# X = df[[col for col in df.columns if col.endswith('_m')]]\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "print(X.columns.tolist())\n",
    "\n",
    "print(\"Splitting data into train and test sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"SVM\": SVC(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"MLP\": MLPClassifier(max_iter=500)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        print(f\"{name} Test accuracy: {acc:.4f}\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        results[name] = acc\n",
    "    except Exception as e:\n",
    "        print(f\"{name} failed: {e}\")\n",
    "\n",
    "print(\"\\nSummary of test accuracies:\")\n",
    "for name, acc in results.items():\n",
    "    print(f\"{name}: {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-thesis_coding-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
